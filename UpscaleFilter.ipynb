{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UpscaleFilter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aklapatch/435-finalproj/blob/master/UpscaleFilter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dfGcwWDr6P2",
        "colab_type": "code",
        "outputId": "dc4e1823-903f-495c-9f2f-f2b38bdbbf94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d19_gBvkx4Wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "f4d7ff72-e9ff-43a6-d024-0f6fc695c895"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-52920cffe44d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_upgrade_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tf_upgrade_v2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqdDbtINsMu6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "dae32240-2b50-435d-d6a1-2490cec79b79"
      },
      "source": [
        "import os, re, math, json, shutil, pprint\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import IPython.display as display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage import data, io, filters\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import array\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "tf.enable_eager_execution()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1146Sh8Ft5ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title visualization utilities [RUN ME]\n",
        "\"\"\"\n",
        "This cell contains helper functions used for visualization\n",
        "and downloads only. You can skip reading it. There is very\n",
        "little useful Keras/Tensorflow code here.\n",
        "\"\"\"\n",
        "\n",
        "# Matplotlib config\n",
        "plt.ioff()\n",
        "plt.rc('image', cmap='gray_r')\n",
        "plt.rc('grid', linewidth=1)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0', figsize=(16,9))\n",
        "# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "\n",
        "# pull a batch from the datasets. This code is not very nice, it gets much better in eager mode (TODO)\n",
        "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
        "  \n",
        "  # get one batch from each: 10000 validation digits, N training digits\n",
        "  batch_train_ds = training_dataset.apply(tf.data.experimental.unbatch()).batch(N)\n",
        "  \n",
        "  # eager execution: loop through datasets normally\n",
        "  if tf.executing_eagerly():\n",
        "    for validation_digits, validation_labels in validation_dataset:\n",
        "      validation_digits = validation_digits.numpy()\n",
        "      validation_labels = validation_labels.numpy()\n",
        "      break\n",
        "    for training_digits, training_labels in batch_train_ds:\n",
        "      training_digits = training_digits.numpy()\n",
        "      training_labels = training_labels.numpy()\n",
        "      break\n",
        "    \n",
        "  else:\n",
        "    v_images, v_labels = validation_dataset.make_one_shot_iterator().get_next()\n",
        "    t_images, t_labels = batch_train_ds.make_one_shot_iterator().get_next()\n",
        "    # Run once, get one batch. Session.run returns numpy results\n",
        "    with tf.Session() as ses:\n",
        "      (validation_digits, validation_labels,\n",
        "       training_digits, training_labels) = ses.run([v_images, v_labels, t_images, t_labels])\n",
        "  \n",
        "  # these were one-hot encoded in the dataset\n",
        "  validation_labels = np.argmax(validation_labels, axis=1)\n",
        "  training_labels = np.argmax(training_labels, axis=1)\n",
        "  \n",
        "  return (training_digits, training_labels,\n",
        "          validation_digits, validation_labels)\n",
        "\n",
        "# create digits from local fonts for testing\n",
        "def create_digits_from_local_fonts(n):\n",
        "  font_labels = []\n",
        "  img = PIL.Image.new('LA', (28*n, 28), color = (0,255)) # format 'LA': black in channel 0, alpha in channel 1\n",
        "  font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n",
        "  font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n",
        "  d = PIL.ImageDraw.Draw(img)\n",
        "  for i in range(n):\n",
        "    font_labels.append(i%10)\n",
        "    d.text((7+i*28,0 if i<10 else -4), str(i%10), fill=(255,255), font=font1 if i<10 else font2)\n",
        "  font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # black in channel 0, alpha in channel 1 (discarded)\n",
        "  font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [28, 28*n]), n, axis=1), axis=0), [n, 28*28])\n",
        "  return font_digits, font_labels\n",
        "\n",
        "# utility to display a row of digits with their predictions\n",
        "def display_digits(digits, predictions, labels, title, n):\n",
        "  fig = plt.figure(figsize=(13,3))\n",
        "  digits = np.reshape(digits, [n, 28, 28])\n",
        "  digits = np.swapaxes(digits, 0, 1)\n",
        "  digits = np.reshape(digits, [28, 28*n])\n",
        "  plt.yticks([])\n",
        "  plt.xticks([28*x+14 for x in range(n)], predictions)\n",
        "  plt.grid(b=None)\n",
        "  for i,t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
        "    if predictions[i] != labels[i]: t.set_color('red') # bad predictions in red\n",
        "  plt.imshow(digits)\n",
        "  plt.grid(None)\n",
        "  plt.title(title)\n",
        "  display.display(fig)\n",
        "  \n",
        "# utility to display multiple rows of digits, sorted by unrecognized/recognized status\n",
        "def display_top_unrecognized(digits, predictions, labels, n, lines):\n",
        "  idx = np.argsort(predictions==labels) # sort order: unrecognized first\n",
        "  for i in range(lines):\n",
        "    display_digits(digits[idx][i*n:(i+1)*n], predictions[idx][i*n:(i+1)*n], labels[idx][i*n:(i+1)*n],\n",
        "                   \"{} sample validation digits out of {} with bad predictions in red and sorted first\".format(n*lines, len(digits)) if i==0 else \"\", n)\n",
        "\n",
        "def plot_learning_rate(lr_func, epochs):\n",
        "  xx = np.arange(epochs+1, dtype=np.float)\n",
        "  y = [lr_decay(x) for x in xx]\n",
        "  fig, ax = plt.subplots(figsize=(9, 6))\n",
        "  ax.set_xlabel('epochs')\n",
        "  ax.set_title('Learning rate\\ndecays from {:0.3g} to {:0.3g}'.format(y[0], y[-2]))\n",
        "  ax.minorticks_on()\n",
        "  ax.grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "  ax.grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "  ax.step(xx,y, linewidth=3, where='post')\n",
        "  display.display(fig)\n",
        "\n",
        "class PlotTraining(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, sample_rate=1, zoom=1):\n",
        "    self.sample_rate = sample_rate\n",
        "    self.step = 0\n",
        "    self.zoom = zoom\n",
        "    self.steps_per_epoch = 60000//BATCH_SIZE\n",
        "\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.batch_history = {}\n",
        "    self.batch_step = []\n",
        "    self.epoch_history = {}\n",
        "    self.epoch_step = []\n",
        "    self.fig, self.axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    plt.ioff()\n",
        "\n",
        "  def on_batch_end(self, batch, logs={}):\n",
        "    if (batch % self.sample_rate) == 0:\n",
        "      self.batch_step.append(self.step)\n",
        "      for k,v in logs.items():\n",
        "        # do not log \"batch\" and \"size\" metrics that do not change\n",
        "        # do not log training accuracy \"acc\"\n",
        "        if k=='batch' or k=='size':# or k=='acc':\n",
        "          continue\n",
        "        self.batch_history.setdefault(k, []).append(v)\n",
        "    self.step += 1\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    plt.close(self.fig)\n",
        "    self.axes[0].cla()\n",
        "    self.axes[1].cla()\n",
        "      \n",
        "    self.axes[0].set_ylim(0, 1.2/self.zoom)\n",
        "    self.axes[1].set_ylim(1-1/self.zoom/2, 1+0.1/self.zoom/2)\n",
        "    \n",
        "    self.epoch_step.append(self.step)\n",
        "    for k,v in logs.items():\n",
        "      # only log validation metrics\n",
        "      if not k.startswith('val_'):\n",
        "        continue\n",
        "      self.epoch_history.setdefault(k, []).append(v)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    \n",
        "    for k,v in self.batch_history.items():\n",
        "      self.axes[0 if k.endswith('loss') else 1].plot(np.array(self.batch_step) / self.steps_per_epoch, v, label=k)\n",
        "      \n",
        "    for k,v in self.epoch_history.items():\n",
        "      self.axes[0 if k.endswith('loss') else 1].plot(np.array(self.epoch_step) / self.steps_per_epoch, v, label=k, linewidth=3)\n",
        "      \n",
        "    self.axes[0].legend()\n",
        "    self.axes[1].legend()\n",
        "    self.axes[0].set_xlabel('epochs')\n",
        "    self.axes[1].set_xlabel('epochs')\n",
        "    self.axes[0].minorticks_on()\n",
        "    self.axes[0].grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "    self.axes[0].grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "    self.axes[1].minorticks_on()\n",
        "    self.axes[1].grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "    self.axes[1].grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "    display.display(self.fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEaUEPDxtyTV",
        "colab_type": "text"
      },
      "source": [
        "Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOBu0D4Ts0-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_path(path):\n",
        "    directories = []\n",
        "    if os.path.isdir(path):\n",
        "        directories.append(path)\n",
        "    for elem in os.listdir(path):\n",
        "        if os.path.isdir(os.path.join(path,elem)):\n",
        "            directories = directories + load_path(os.path.join(path,elem))\n",
        "            directories.append(os.path.join(path,elem))\n",
        "    return directories\n",
        "\n",
        "def normalize(input_data):\n",
        "\n",
        "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
        "    \n",
        "def denormalize(input_data):\n",
        "    input_data = (input_data + 1) * 127.5\n",
        "    return input_data.astype(np.uint8)\n",
        "\n",
        "def load_data_from_dirs(dirs, ext,num_files):\n",
        "    files = []\n",
        "    file_names = []\n",
        "    count = 0\n",
        "    for d in dirs:\n",
        "        for f in os.listdir(d): \n",
        "            if f.endswith(ext):\n",
        "                image = io.imread(os.path.join(d,f))\n",
        "                if len(image.shape) > 2:\n",
        "                    files.append(image)\n",
        "                    if len(files) >= num_files:\n",
        "                        return files\n",
        "                    file_names.append(os.path.join(d,f))\n",
        "                count = count + 1\n",
        "    return files \n",
        "\n",
        "def load_training_data(directory, ext, number_of_images = 1000):    \n",
        "    files = load_data_from_dirs(load_path(directory), ext, number_of_images)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    test_array = array(files)\n",
        "    if len(test_array.shape) < 3:\n",
        "        print(\"Images are of not same shape\")\n",
        "        print(\"Please provide same shape images\")\n",
        "        sys.exit()\n",
        "    \n",
        "    return test_array\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_CBH8fWt00Z",
        "colab_type": "text"
      },
      "source": [
        "Loading data from Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byvFHzqwt5FE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "imgnum = 800\n",
        "target_imgs = load_training_data(\"/content/drive/My Drive/ALOT384/\",\"jpg\", imgnum)\n",
        "input_imgs = load_training_data(\"/content/drive/My Drive/ALOTdown&UpScaled/\", \"jpg\", imgnum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pczIC3ABwHxe",
        "colab_type": "text"
      },
      "source": [
        "Init the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdTS6_StwMNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputTensor = Input(shape=(384,384,3))\n",
        "x = UpSampling2D(size=(2,2),data_format=\"channels_last\",interpolation=\"bilinear\")(inputTensor)\n",
        "x = Conv2D(3,(5,5),data_format=\"channels_last\",activation='relu',padding=\"same\")(x)\n",
        "x = MaxPooling2D((2,2), padding='same')(x)\n",
        "x = Conv2D(3, (5,5),data_format=\"channels_last\", activation='relu', padding='same')(x)\n",
        "\n",
        "model = Model(inputTensor, x)\n",
        "model.compile(optimizer='sgd', loss='mean_absolute_error', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lzaffrBLSG2",
        "colab_type": "text"
      },
      "source": [
        "data set of 500 images\n",
        "### Optimizers\n",
        "*   SGD: about .58 acc and does not get better\n",
        "*   Adam: worse than sgd\n",
        "\n",
        "### Misc\n",
        "- a 5,5 convolution is better than 3,3 it seems\n",
        "- but a 7,7 is not really better than a 5,5\n",
        "- a 9,9 takes longer to get to .578 acc, but it gets there, It trains much slower\n",
        "- batch size does not affect accuracy it seems\n",
        "- changing image sample size to 800 kicks the acc down to .16 at the beginning\n",
        "- using 2 Conv2D filters seems to only be able to get .578 acc at max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiPJKgnv5lb6",
        "colab_type": "text"
      },
      "source": [
        "Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlZPKiuS6YzZ",
        "colab_type": "code",
        "outputId": "57838890-a437-4578-fea2-ce2ce3097d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "plot = PlotTraining(sample_rate=10, zoom=1)\n",
        "\n",
        "# the number of epochs\n",
        "epochs = 1000\n",
        "pocsperloop=100\n",
        "eps = int(epochs/pocsperloop)\n",
        "for e in range(1, eps+1):\n",
        "  print(\"iteration %2d/%2d\" % (e, eps))\n",
        "  model.fit(input_imgs, \n",
        "            target_imgs, \n",
        "            epochs=pocsperloop,\n",
        "            batch_size=128,\n",
        "            shuffle=True,\n",
        "            validation_split=0.05\n",
        "            callbacks=[plot])\n",
        "  print(\"saving model\")\n",
        "  model.save(\"/content/drive/My Drive/models/last_model.h5\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration  1/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 3s 4ms/step - loss: 81.2116 - acc: 0.1681 - val_loss: 40.2586 - val_acc: 0.1556\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.2014 - acc: 0.1681 - val_loss: 40.2492 - val_acc: 0.1556\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1913 - acc: 0.1681 - val_loss: 40.2397 - val_acc: 0.1556\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1811 - acc: 0.1681 - val_loss: 40.2303 - val_acc: 0.1556\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1710 - acc: 0.1681 - val_loss: 40.2208 - val_acc: 0.1556\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1607 - acc: 0.1681 - val_loss: 40.2114 - val_acc: 0.1556\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1507 - acc: 0.1681 - val_loss: 40.2020 - val_acc: 0.1556\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1406 - acc: 0.1681 - val_loss: 40.1931 - val_acc: 0.1557\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1309 - acc: 0.1681 - val_loss: 40.1842 - val_acc: 0.1557\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1213 - acc: 0.1681 - val_loss: 40.1753 - val_acc: 0.1557\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1118 - acc: 0.1682 - val_loss: 40.1669 - val_acc: 0.1557\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.1025 - acc: 0.1682 - val_loss: 40.1587 - val_acc: 0.1558\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0936 - acc: 0.1682 - val_loss: 40.1506 - val_acc: 0.1558\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0846 - acc: 0.1682 - val_loss: 40.1426 - val_acc: 0.1558\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0756 - acc: 0.1682 - val_loss: 40.1344 - val_acc: 0.1558\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0667 - acc: 0.1682 - val_loss: 40.1264 - val_acc: 0.1558\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0578 - acc: 0.1682 - val_loss: 40.1183 - val_acc: 0.1558\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0488 - acc: 0.1682 - val_loss: 40.1103 - val_acc: 0.1558\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0399 - acc: 0.1682 - val_loss: 40.1022 - val_acc: 0.1558\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0310 - acc: 0.1682 - val_loss: 40.0941 - val_acc: 0.1558\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0220 - acc: 0.1682 - val_loss: 40.0860 - val_acc: 0.1559\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0131 - acc: 0.1682 - val_loss: 40.0780 - val_acc: 0.1559\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 81.0042 - acc: 0.1682 - val_loss: 40.0699 - val_acc: 0.1559\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9952 - acc: 0.1682 - val_loss: 40.0618 - val_acc: 0.1559\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9863 - acc: 0.1682 - val_loss: 40.0537 - val_acc: 0.1559\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9774 - acc: 0.1682 - val_loss: 40.0456 - val_acc: 0.1560\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9684 - acc: 0.1682 - val_loss: 40.0376 - val_acc: 0.1560\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9595 - acc: 0.1682 - val_loss: 40.0295 - val_acc: 0.1560\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9506 - acc: 0.1682 - val_loss: 40.0214 - val_acc: 0.1560\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9416 - acc: 0.1682 - val_loss: 40.0133 - val_acc: 0.1561\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9327 - acc: 0.1682 - val_loss: 40.0053 - val_acc: 0.1561\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9238 - acc: 0.1682 - val_loss: 39.9972 - val_acc: 0.1561\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9148 - acc: 0.1682 - val_loss: 39.9892 - val_acc: 0.1561\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.9059 - acc: 0.1682 - val_loss: 39.9811 - val_acc: 0.1561\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8970 - acc: 0.1682 - val_loss: 39.9730 - val_acc: 0.1561\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8880 - acc: 0.1682 - val_loss: 39.9649 - val_acc: 0.1561\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8791 - acc: 0.1682 - val_loss: 39.9569 - val_acc: 0.1562\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8702 - acc: 0.1682 - val_loss: 39.9488 - val_acc: 0.1562\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8612 - acc: 0.1682 - val_loss: 39.9407 - val_acc: 0.1562\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8523 - acc: 0.1682 - val_loss: 39.9326 - val_acc: 0.1562\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8434 - acc: 0.1683 - val_loss: 39.9246 - val_acc: 0.1562\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8344 - acc: 0.1683 - val_loss: 39.9165 - val_acc: 0.1562\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8255 - acc: 0.1683 - val_loss: 39.9084 - val_acc: 0.1563\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8166 - acc: 0.1683 - val_loss: 39.9003 - val_acc: 0.1563\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.8076 - acc: 0.1683 - val_loss: 39.8923 - val_acc: 0.1563\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7987 - acc: 0.1683 - val_loss: 39.8842 - val_acc: 0.1563\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7897 - acc: 0.1683 - val_loss: 39.8761 - val_acc: 0.1563\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7808 - acc: 0.1683 - val_loss: 39.8680 - val_acc: 0.1563\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7719 - acc: 0.1683 - val_loss: 39.8599 - val_acc: 0.1564\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7629 - acc: 0.1683 - val_loss: 39.8518 - val_acc: 0.1564\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7540 - acc: 0.1683 - val_loss: 39.8438 - val_acc: 0.1564\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7451 - acc: 0.1683 - val_loss: 39.8357 - val_acc: 0.1564\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7361 - acc: 0.1683 - val_loss: 39.8276 - val_acc: 0.1564\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7272 - acc: 0.1683 - val_loss: 39.8195 - val_acc: 0.1565\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7183 - acc: 0.1683 - val_loss: 39.8114 - val_acc: 0.1565\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7093 - acc: 0.1684 - val_loss: 39.8033 - val_acc: 0.1565\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.7004 - acc: 0.1684 - val_loss: 39.7953 - val_acc: 0.1565\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6914 - acc: 0.1684 - val_loss: 39.7872 - val_acc: 0.1565\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6825 - acc: 0.1684 - val_loss: 39.7792 - val_acc: 0.1566\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6736 - acc: 0.1684 - val_loss: 39.7710 - val_acc: 0.1566\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6647 - acc: 0.1684 - val_loss: 39.7630 - val_acc: 0.1566\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6557 - acc: 0.1685 - val_loss: 39.7549 - val_acc: 0.1566\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6468 - acc: 0.1685 - val_loss: 39.7468 - val_acc: 0.1567\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6378 - acc: 0.1685 - val_loss: 39.7387 - val_acc: 0.1567\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6289 - acc: 0.1685 - val_loss: 39.7306 - val_acc: 0.1567\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6199 - acc: 0.1686 - val_loss: 39.7225 - val_acc: 0.1568\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6110 - acc: 0.1688 - val_loss: 39.7144 - val_acc: 0.1569\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.6020 - acc: 0.1688 - val_loss: 39.7064 - val_acc: 0.1569\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5931 - acc: 0.1688 - val_loss: 39.6983 - val_acc: 0.1569\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5842 - acc: 0.1688 - val_loss: 39.6902 - val_acc: 0.1569\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5752 - acc: 0.1689 - val_loss: 39.6821 - val_acc: 0.1570\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5663 - acc: 0.1689 - val_loss: 39.6741 - val_acc: 0.1570\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5574 - acc: 0.1689 - val_loss: 39.6660 - val_acc: 0.1571\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5484 - acc: 0.1690 - val_loss: 39.6579 - val_acc: 0.1571\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5395 - acc: 0.1690 - val_loss: 39.6498 - val_acc: 0.1571\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5306 - acc: 0.1690 - val_loss: 39.6417 - val_acc: 0.1571\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5216 - acc: 0.1690 - val_loss: 39.6336 - val_acc: 0.1572\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5127 - acc: 0.1691 - val_loss: 39.6256 - val_acc: 0.1572\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.5037 - acc: 0.1691 - val_loss: 39.6174 - val_acc: 0.1573\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 3s 3ms/step - loss: 80.4948 - acc: 0.1691 - val_loss: 39.6094 - val_acc: 0.1573\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4859 - acc: 0.1692 - val_loss: 39.6013 - val_acc: 0.1573\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4770 - acc: 0.1692 - val_loss: 39.5932 - val_acc: 0.1574\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4680 - acc: 0.1692 - val_loss: 39.5853 - val_acc: 0.1574\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4593 - acc: 0.1693 - val_loss: 39.5775 - val_acc: 0.1575\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4508 - acc: 0.1695 - val_loss: 39.5700 - val_acc: 0.1575\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4424 - acc: 0.1695 - val_loss: 39.5625 - val_acc: 0.1576\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4339 - acc: 0.1696 - val_loss: 39.5550 - val_acc: 0.1576\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4256 - acc: 0.1696 - val_loss: 39.5477 - val_acc: 0.1577\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4175 - acc: 0.1697 - val_loss: 39.5406 - val_acc: 0.1578\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4092 - acc: 0.1698 - val_loss: 39.5333 - val_acc: 0.1578\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.4011 - acc: 0.1698 - val_loss: 39.5261 - val_acc: 0.1579\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3929 - acc: 0.1699 - val_loss: 39.5189 - val_acc: 0.1580\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3847 - acc: 0.1700 - val_loss: 39.5116 - val_acc: 0.1580\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3765 - acc: 0.1700 - val_loss: 39.5044 - val_acc: 0.1582\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3684 - acc: 0.1703 - val_loss: 39.4971 - val_acc: 0.1583\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3602 - acc: 0.1704 - val_loss: 39.4899 - val_acc: 0.1584\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3520 - acc: 0.1705 - val_loss: 39.4826 - val_acc: 0.1585\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3438 - acc: 0.1706 - val_loss: 39.4753 - val_acc: 0.1586\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3356 - acc: 0.1707 - val_loss: 39.4680 - val_acc: 0.1587\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3274 - acc: 0.1708 - val_loss: 39.4607 - val_acc: 0.1589\n",
            "saving model\n",
            "iteration  2/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3192 - acc: 0.1710 - val_loss: 39.4533 - val_acc: 0.1591\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3109 - acc: 0.3675 - val_loss: 39.4459 - val_acc: 0.7460\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.3026 - acc: 0.5325 - val_loss: 39.4385 - val_acc: 0.7459\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2943 - acc: 0.5325 - val_loss: 39.4310 - val_acc: 0.7456\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2860 - acc: 0.5322 - val_loss: 39.4234 - val_acc: 0.7452\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2776 - acc: 0.5317 - val_loss: 39.4156 - val_acc: 0.7447\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2690 - acc: 0.5312 - val_loss: 39.4074 - val_acc: 0.7441\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2598 - acc: 0.5306 - val_loss: 39.3986 - val_acc: 0.7428\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2496 - acc: 0.5295 - val_loss: 39.3884 - val_acc: 0.7407\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2363 - acc: 0.5277 - val_loss: 39.3366 - val_acc: 0.7283\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6599 - acc: 0.4663 - val_loss: 39.3856 - val_acc: 0.7527\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2321 - acc: 0.5658 - val_loss: 39.3784 - val_acc: 0.7527\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2239 - acc: 0.5658 - val_loss: 39.3712 - val_acc: 0.7527\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2158 - acc: 0.5659 - val_loss: 39.3641 - val_acc: 0.7528\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.2076 - acc: 0.5659 - val_loss: 39.3569 - val_acc: 0.7528\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1995 - acc: 0.5659 - val_loss: 39.3498 - val_acc: 0.7528\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1914 - acc: 0.5659 - val_loss: 39.3426 - val_acc: 0.7528\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1832 - acc: 0.5659 - val_loss: 39.3355 - val_acc: 0.7528\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1751 - acc: 0.5659 - val_loss: 39.3283 - val_acc: 0.7528\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1669 - acc: 0.5659 - val_loss: 39.3212 - val_acc: 0.7528\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1588 - acc: 0.5659 - val_loss: 39.3140 - val_acc: 0.7528\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1506 - acc: 0.5660 - val_loss: 39.3068 - val_acc: 0.7529\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1425 - acc: 0.5660 - val_loss: 39.2997 - val_acc: 0.7529\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1344 - acc: 0.5660 - val_loss: 39.2926 - val_acc: 0.7529\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1262 - acc: 0.5660 - val_loss: 39.2854 - val_acc: 0.7529\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1181 - acc: 0.5660 - val_loss: 39.2783 - val_acc: 0.7529\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1100 - acc: 0.5660 - val_loss: 39.2710 - val_acc: 0.7529\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.1018 - acc: 0.5660 - val_loss: 39.2639 - val_acc: 0.7529\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0937 - acc: 0.5660 - val_loss: 39.2568 - val_acc: 0.7529\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0856 - acc: 0.5660 - val_loss: 39.2497 - val_acc: 0.7529\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0774 - acc: 0.5660 - val_loss: 39.2425 - val_acc: 0.7529\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0693 - acc: 0.5660 - val_loss: 39.2353 - val_acc: 0.7529\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0611 - acc: 0.5660 - val_loss: 39.2282 - val_acc: 0.7530\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0530 - acc: 0.5661 - val_loss: 39.2210 - val_acc: 0.7530\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0449 - acc: 0.5661 - val_loss: 39.2139 - val_acc: 0.7530\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0367 - acc: 0.5661 - val_loss: 39.2067 - val_acc: 0.7530\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0286 - acc: 0.5661 - val_loss: 39.1995 - val_acc: 0.7530\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0204 - acc: 0.5661 - val_loss: 39.1924 - val_acc: 0.7530\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0123 - acc: 0.5661 - val_loss: 39.1852 - val_acc: 0.7530\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 80.0041 - acc: 0.5661 - val_loss: 39.1781 - val_acc: 0.7530\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9961 - acc: 0.5661 - val_loss: 39.1709 - val_acc: 0.7530\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9879 - acc: 0.5661 - val_loss: 39.1638 - val_acc: 0.7530\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9797 - acc: 0.5661 - val_loss: 39.1566 - val_acc: 0.7530\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9716 - acc: 0.5661 - val_loss: 39.1494 - val_acc: 0.7530\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9634 - acc: 0.5661 - val_loss: 39.1423 - val_acc: 0.7530\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9553 - acc: 0.5661 - val_loss: 39.1351 - val_acc: 0.7530\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9472 - acc: 0.5661 - val_loss: 39.1280 - val_acc: 0.7530\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9391 - acc: 0.5661 - val_loss: 39.1208 - val_acc: 0.7531\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9309 - acc: 0.5661 - val_loss: 39.1136 - val_acc: 0.7531\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9228 - acc: 0.5661 - val_loss: 39.1065 - val_acc: 0.7531\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9146 - acc: 0.5662 - val_loss: 39.0994 - val_acc: 0.7531\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.9065 - acc: 0.5662 - val_loss: 39.0922 - val_acc: 0.7531\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8983 - acc: 0.5662 - val_loss: 39.0850 - val_acc: 0.7531\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8903 - acc: 0.5662 - val_loss: 39.0779 - val_acc: 0.7531\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8821 - acc: 0.5662 - val_loss: 39.0708 - val_acc: 0.7531\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8740 - acc: 0.5662 - val_loss: 39.0636 - val_acc: 0.7531\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8659 - acc: 0.5662 - val_loss: 39.0565 - val_acc: 0.7531\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8577 - acc: 0.5662 - val_loss: 39.0493 - val_acc: 0.7531\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8496 - acc: 0.5662 - val_loss: 39.0423 - val_acc: 0.7531\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8416 - acc: 0.5662 - val_loss: 39.0353 - val_acc: 0.7531\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8337 - acc: 0.5662 - val_loss: 39.0283 - val_acc: 0.7531\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8258 - acc: 0.5662 - val_loss: 39.0214 - val_acc: 0.7531\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8178 - acc: 0.5662 - val_loss: 39.0147 - val_acc: 0.7531\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8101 - acc: 0.5662 - val_loss: 39.0080 - val_acc: 0.7531\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.8024 - acc: 0.5662 - val_loss: 39.0012 - val_acc: 0.7531\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7946 - acc: 0.5662 - val_loss: 38.9945 - val_acc: 0.7531\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7869 - acc: 0.5662 - val_loss: 38.9878 - val_acc: 0.7531\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7791 - acc: 0.5662 - val_loss: 38.9811 - val_acc: 0.7531\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7714 - acc: 0.5662 - val_loss: 38.9746 - val_acc: 0.7531\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7638 - acc: 0.5662 - val_loss: 38.9681 - val_acc: 0.7531\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7563 - acc: 0.5662 - val_loss: 38.9617 - val_acc: 0.7531\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7487 - acc: 0.5662 - val_loss: 38.9553 - val_acc: 0.7531\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7413 - acc: 0.5662 - val_loss: 38.9489 - val_acc: 0.7531\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7337 - acc: 0.5662 - val_loss: 38.9424 - val_acc: 0.7531\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7261 - acc: 0.5662 - val_loss: 38.9359 - val_acc: 0.7531\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7187 - acc: 0.5662 - val_loss: 38.9295 - val_acc: 0.7531\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7111 - acc: 0.5662 - val_loss: 38.9231 - val_acc: 0.7531\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.7036 - acc: 0.5662 - val_loss: 38.9167 - val_acc: 0.7531\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6960 - acc: 0.5662 - val_loss: 38.9102 - val_acc: 0.7531\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6885 - acc: 0.5662 - val_loss: 38.9038 - val_acc: 0.7531\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6810 - acc: 0.5662 - val_loss: 38.8973 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6734 - acc: 0.5662 - val_loss: 38.8909 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6659 - acc: 0.5663 - val_loss: 38.8844 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6583 - acc: 0.5663 - val_loss: 38.8780 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6509 - acc: 0.5663 - val_loss: 38.8716 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6433 - acc: 0.5663 - val_loss: 38.8652 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6358 - acc: 0.5663 - val_loss: 38.8587 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6282 - acc: 0.5663 - val_loss: 38.8523 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6207 - acc: 0.5663 - val_loss: 38.8458 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6132 - acc: 0.5663 - val_loss: 38.8394 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.6056 - acc: 0.5663 - val_loss: 38.8330 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5981 - acc: 0.5663 - val_loss: 38.8265 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5905 - acc: 0.5663 - val_loss: 38.8201 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5831 - acc: 0.5663 - val_loss: 38.8137 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5756 - acc: 0.5663 - val_loss: 38.8072 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5680 - acc: 0.5663 - val_loss: 38.8008 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5604 - acc: 0.5663 - val_loss: 38.7944 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5529 - acc: 0.5663 - val_loss: 38.7879 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5454 - acc: 0.5663 - val_loss: 38.7815 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5379 - acc: 0.5663 - val_loss: 38.7750 - val_acc: 0.7532\n",
            "saving model\n",
            "iteration  3/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5303 - acc: 0.5663 - val_loss: 38.7686 - val_acc: 0.7532\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5228 - acc: 0.5663 - val_loss: 38.7622 - val_acc: 0.7532\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5153 - acc: 0.5663 - val_loss: 38.7558 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5077 - acc: 0.5663 - val_loss: 38.7493 - val_acc: 0.7532\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.5002 - acc: 0.5663 - val_loss: 38.7428 - val_acc: 0.7532\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4927 - acc: 0.5663 - val_loss: 38.7364 - val_acc: 0.7532\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4851 - acc: 0.5663 - val_loss: 38.7300 - val_acc: 0.7532\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4776 - acc: 0.5663 - val_loss: 38.7236 - val_acc: 0.7532\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4701 - acc: 0.5663 - val_loss: 38.7171 - val_acc: 0.7532\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4626 - acc: 0.5663 - val_loss: 38.7107 - val_acc: 0.7532\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4550 - acc: 0.5663 - val_loss: 38.7042 - val_acc: 0.7532\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4475 - acc: 0.5663 - val_loss: 38.6978 - val_acc: 0.7532\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4400 - acc: 0.5663 - val_loss: 38.6914 - val_acc: 0.7532\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4324 - acc: 0.5663 - val_loss: 38.6849 - val_acc: 0.7532\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4249 - acc: 0.5663 - val_loss: 38.6785 - val_acc: 0.7532\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4173 - acc: 0.5663 - val_loss: 38.6721 - val_acc: 0.7532\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4099 - acc: 0.5663 - val_loss: 38.6656 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.4022 - acc: 0.5663 - val_loss: 38.6592 - val_acc: 0.7532\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3947 - acc: 0.5663 - val_loss: 38.6527 - val_acc: 0.7532\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3872 - acc: 0.5663 - val_loss: 38.6463 - val_acc: 0.7532\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3797 - acc: 0.5663 - val_loss: 38.6399 - val_acc: 0.7532\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3721 - acc: 0.5663 - val_loss: 38.6334 - val_acc: 0.7532\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3646 - acc: 0.5663 - val_loss: 38.6270 - val_acc: 0.7532\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3571 - acc: 0.5663 - val_loss: 38.6205 - val_acc: 0.7532\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3496 - acc: 0.5663 - val_loss: 38.6141 - val_acc: 0.7532\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3420 - acc: 0.5663 - val_loss: 38.6077 - val_acc: 0.7532\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3345 - acc: 0.5663 - val_loss: 38.6013 - val_acc: 0.7532\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3270 - acc: 0.5663 - val_loss: 38.5948 - val_acc: 0.7532\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3195 - acc: 0.5663 - val_loss: 38.5884 - val_acc: 0.7532\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3119 - acc: 0.5663 - val_loss: 38.5820 - val_acc: 0.7532\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.3044 - acc: 0.5663 - val_loss: 38.5755 - val_acc: 0.7532\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2969 - acc: 0.5663 - val_loss: 38.5691 - val_acc: 0.7532\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2894 - acc: 0.5663 - val_loss: 38.5627 - val_acc: 0.7532\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2819 - acc: 0.5663 - val_loss: 38.5562 - val_acc: 0.7532\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2743 - acc: 0.5663 - val_loss: 38.5498 - val_acc: 0.7532\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 3s 3ms/step - loss: 79.2668 - acc: 0.5663 - val_loss: 38.5434 - val_acc: 0.7532\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2593 - acc: 0.5663 - val_loss: 38.5371 - val_acc: 0.7532\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2519 - acc: 0.5663 - val_loss: 38.5308 - val_acc: 0.7532\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2446 - acc: 0.5663 - val_loss: 38.5246 - val_acc: 0.7532\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2372 - acc: 0.5663 - val_loss: 38.5183 - val_acc: 0.7532\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2298 - acc: 0.5663 - val_loss: 38.5121 - val_acc: 0.7532\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2225 - acc: 0.5663 - val_loss: 38.5058 - val_acc: 0.7532\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2151 - acc: 0.5663 - val_loss: 38.4995 - val_acc: 0.7532\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2077 - acc: 0.5663 - val_loss: 38.4933 - val_acc: 0.7532\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.2004 - acc: 0.5663 - val_loss: 38.4872 - val_acc: 0.7532\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1931 - acc: 0.5663 - val_loss: 38.4811 - val_acc: 0.7532\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1859 - acc: 0.5663 - val_loss: 38.4750 - val_acc: 0.7532\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1787 - acc: 0.5663 - val_loss: 38.4690 - val_acc: 0.7532\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1715 - acc: 0.5663 - val_loss: 38.4629 - val_acc: 0.7532\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1643 - acc: 0.5663 - val_loss: 38.4568 - val_acc: 0.7532\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1571 - acc: 0.5663 - val_loss: 38.4508 - val_acc: 0.7532\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1498 - acc: 0.5663 - val_loss: 38.4448 - val_acc: 0.7532\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1426 - acc: 0.5663 - val_loss: 38.4387 - val_acc: 0.7532\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1355 - acc: 0.5663 - val_loss: 38.4328 - val_acc: 0.7532\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1285 - acc: 0.5663 - val_loss: 38.4270 - val_acc: 0.7532\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1215 - acc: 0.5663 - val_loss: 38.4212 - val_acc: 0.7532\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1145 - acc: 0.5663 - val_loss: 38.4154 - val_acc: 0.7532\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1074 - acc: 0.5663 - val_loss: 38.4095 - val_acc: 0.7532\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.1004 - acc: 0.5663 - val_loss: 38.4037 - val_acc: 0.7532\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0934 - acc: 0.5663 - val_loss: 38.3979 - val_acc: 0.7532\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0864 - acc: 0.5663 - val_loss: 38.3921 - val_acc: 0.7532\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0794 - acc: 0.5663 - val_loss: 38.3863 - val_acc: 0.7532\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0723 - acc: 0.5663 - val_loss: 38.3804 - val_acc: 0.7532\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0653 - acc: 0.5663 - val_loss: 38.3746 - val_acc: 0.7532\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0583 - acc: 0.5663 - val_loss: 38.3687 - val_acc: 0.7532\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0513 - acc: 0.5663 - val_loss: 38.3630 - val_acc: 0.7532\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0443 - acc: 0.5663 - val_loss: 38.3571 - val_acc: 0.7532\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0372 - acc: 0.5663 - val_loss: 38.3513 - val_acc: 0.7532\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0302 - acc: 0.5663 - val_loss: 38.3455 - val_acc: 0.7532\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0232 - acc: 0.5663 - val_loss: 38.3397 - val_acc: 0.7532\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0162 - acc: 0.5663 - val_loss: 38.3338 - val_acc: 0.7532\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0092 - acc: 0.5663 - val_loss: 38.3280 - val_acc: 0.7532\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 79.0022 - acc: 0.5663 - val_loss: 38.3222 - val_acc: 0.7532\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9951 - acc: 0.5663 - val_loss: 38.3164 - val_acc: 0.7532\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9881 - acc: 0.5663 - val_loss: 38.3106 - val_acc: 0.7532\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9811 - acc: 0.5663 - val_loss: 38.3047 - val_acc: 0.7532\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9741 - acc: 0.5663 - val_loss: 38.2989 - val_acc: 0.7532\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9671 - acc: 0.5663 - val_loss: 38.2931 - val_acc: 0.7532\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9601 - acc: 0.5663 - val_loss: 38.2873 - val_acc: 0.7532\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9531 - acc: 0.5663 - val_loss: 38.2814 - val_acc: 0.7532\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9460 - acc: 0.5663 - val_loss: 38.2756 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9391 - acc: 0.5663 - val_loss: 38.2697 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9320 - acc: 0.5663 - val_loss: 38.2639 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9250 - acc: 0.5663 - val_loss: 38.2581 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9180 - acc: 0.5663 - val_loss: 38.2523 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9109 - acc: 0.5663 - val_loss: 38.2465 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.9040 - acc: 0.5663 - val_loss: 38.2407 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8969 - acc: 0.5663 - val_loss: 38.2349 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8899 - acc: 0.5663 - val_loss: 38.2290 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8829 - acc: 0.5663 - val_loss: 38.2232 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8759 - acc: 0.5663 - val_loss: 38.2174 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8689 - acc: 0.5663 - val_loss: 38.2115 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8619 - acc: 0.5663 - val_loss: 38.2057 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8548 - acc: 0.5663 - val_loss: 38.1999 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8479 - acc: 0.5663 - val_loss: 38.1940 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8408 - acc: 0.5663 - val_loss: 38.1882 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8338 - acc: 0.5663 - val_loss: 38.1824 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8268 - acc: 0.5663 - val_loss: 38.1766 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8198 - acc: 0.5663 - val_loss: 38.1708 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8128 - acc: 0.5663 - val_loss: 38.1650 - val_acc: 0.7532\n",
            "saving model\n",
            "iteration  4/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.8058 - acc: 0.5663 - val_loss: 38.1592 - val_acc: 0.7532\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7988 - acc: 0.5663 - val_loss: 38.1533 - val_acc: 0.7532\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7917 - acc: 0.5663 - val_loss: 38.1476 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7847 - acc: 0.5663 - val_loss: 38.1417 - val_acc: 0.7532\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7777 - acc: 0.5663 - val_loss: 38.1359 - val_acc: 0.7532\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7707 - acc: 0.5664 - val_loss: 38.1301 - val_acc: 0.7532\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7637 - acc: 0.5664 - val_loss: 38.1242 - val_acc: 0.7532\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7567 - acc: 0.5664 - val_loss: 38.1184 - val_acc: 0.7532\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7497 - acc: 0.5664 - val_loss: 38.1126 - val_acc: 0.7532\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7427 - acc: 0.5664 - val_loss: 38.1068 - val_acc: 0.7532\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7356 - acc: 0.5664 - val_loss: 38.1010 - val_acc: 0.7532\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7287 - acc: 0.5664 - val_loss: 38.0951 - val_acc: 0.7532\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7216 - acc: 0.5664 - val_loss: 38.0893 - val_acc: 0.7532\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7146 - acc: 0.5664 - val_loss: 38.0835 - val_acc: 0.7532\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7076 - acc: 0.5664 - val_loss: 38.0777 - val_acc: 0.7532\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.7006 - acc: 0.5664 - val_loss: 38.0719 - val_acc: 0.7532\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6936 - acc: 0.5664 - val_loss: 38.0662 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6867 - acc: 0.5664 - val_loss: 38.0605 - val_acc: 0.7532\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6798 - acc: 0.5664 - val_loss: 38.0548 - val_acc: 0.7532\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6729 - acc: 0.5664 - val_loss: 38.0491 - val_acc: 0.7532\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6661 - acc: 0.5664 - val_loss: 38.0435 - val_acc: 0.7532\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6591 - acc: 0.5664 - val_loss: 38.0377 - val_acc: 0.7532\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6523 - acc: 0.5664 - val_loss: 38.0321 - val_acc: 0.7532\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6454 - acc: 0.5664 - val_loss: 38.0264 - val_acc: 0.7532\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6385 - acc: 0.5664 - val_loss: 38.0207 - val_acc: 0.7532\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6316 - acc: 0.5664 - val_loss: 38.0150 - val_acc: 0.7532\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6247 - acc: 0.5664 - val_loss: 38.0093 - val_acc: 0.7532\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6178 - acc: 0.5664 - val_loss: 38.0036 - val_acc: 0.7532\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6109 - acc: 0.5664 - val_loss: 37.9979 - val_acc: 0.7532\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.6040 - acc: 0.5664 - val_loss: 37.9922 - val_acc: 0.7532\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5971 - acc: 0.5664 - val_loss: 37.9867 - val_acc: 0.7532\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5903 - acc: 0.5664 - val_loss: 37.9812 - val_acc: 0.7532\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5836 - acc: 0.5664 - val_loss: 37.9757 - val_acc: 0.7532\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5767 - acc: 0.5664 - val_loss: 37.9702 - val_acc: 0.7532\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5700 - acc: 0.5664 - val_loss: 37.9647 - val_acc: 0.7532\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5632 - acc: 0.5664 - val_loss: 37.9592 - val_acc: 0.7532\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5564 - acc: 0.5664 - val_loss: 37.9536 - val_acc: 0.7532\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5496 - acc: 0.5664 - val_loss: 37.9482 - val_acc: 0.7532\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5429 - acc: 0.5664 - val_loss: 37.9426 - val_acc: 0.7532\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5361 - acc: 0.5664 - val_loss: 37.9371 - val_acc: 0.7532\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5293 - acc: 0.5664 - val_loss: 37.9316 - val_acc: 0.7532\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5225 - acc: 0.5664 - val_loss: 37.9261 - val_acc: 0.7532\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5159 - acc: 0.5664 - val_loss: 37.9208 - val_acc: 0.7532\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5092 - acc: 0.5664 - val_loss: 37.9155 - val_acc: 0.7532\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.5026 - acc: 0.5664 - val_loss: 37.9101 - val_acc: 0.7532\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4960 - acc: 0.5664 - val_loss: 37.9049 - val_acc: 0.7532\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4894 - acc: 0.5664 - val_loss: 37.8995 - val_acc: 0.7532\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4827 - acc: 0.5664 - val_loss: 37.8942 - val_acc: 0.7532\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4761 - acc: 0.5664 - val_loss: 37.8889 - val_acc: 0.7532\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4695 - acc: 0.5664 - val_loss: 37.8836 - val_acc: 0.7532\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4629 - acc: 0.5664 - val_loss: 37.8782 - val_acc: 0.7532\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4563 - acc: 0.5664 - val_loss: 37.8729 - val_acc: 0.7532\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4497 - acc: 0.5664 - val_loss: 37.8676 - val_acc: 0.7532\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4431 - acc: 0.5664 - val_loss: 37.8623 - val_acc: 0.7532\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4364 - acc: 0.5664 - val_loss: 37.8569 - val_acc: 0.7532\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4298 - acc: 0.5664 - val_loss: 37.8516 - val_acc: 0.7532\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4232 - acc: 0.5664 - val_loss: 37.8462 - val_acc: 0.7532\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4165 - acc: 0.5664 - val_loss: 37.8410 - val_acc: 0.7532\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4099 - acc: 0.5664 - val_loss: 37.8356 - val_acc: 0.7532\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.4033 - acc: 0.5664 - val_loss: 37.8303 - val_acc: 0.7532\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3967 - acc: 0.5664 - val_loss: 37.8250 - val_acc: 0.7532\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3901 - acc: 0.5664 - val_loss: 37.8197 - val_acc: 0.7532\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3835 - acc: 0.5664 - val_loss: 37.8144 - val_acc: 0.7532\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3769 - acc: 0.5664 - val_loss: 37.8090 - val_acc: 0.7532\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3702 - acc: 0.5664 - val_loss: 37.8037 - val_acc: 0.7532\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3636 - acc: 0.5664 - val_loss: 37.7984 - val_acc: 0.7532\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3570 - acc: 0.5664 - val_loss: 37.7930 - val_acc: 0.7532\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3504 - acc: 0.5664 - val_loss: 37.7877 - val_acc: 0.7532\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3437 - acc: 0.5664 - val_loss: 37.7824 - val_acc: 0.7532\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3371 - acc: 0.5664 - val_loss: 37.7771 - val_acc: 0.7532\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3305 - acc: 0.5664 - val_loss: 37.7718 - val_acc: 0.7532\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3239 - acc: 0.5664 - val_loss: 37.7664 - val_acc: 0.7532\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3173 - acc: 0.5664 - val_loss: 37.7611 - val_acc: 0.7532\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3107 - acc: 0.5664 - val_loss: 37.7558 - val_acc: 0.7532\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.3041 - acc: 0.5664 - val_loss: 37.7505 - val_acc: 0.7532\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2975 - acc: 0.5664 - val_loss: 37.7452 - val_acc: 0.7532\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2908 - acc: 0.5664 - val_loss: 37.7399 - val_acc: 0.7532\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2842 - acc: 0.5664 - val_loss: 37.7345 - val_acc: 0.7532\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2777 - acc: 0.5664 - val_loss: 37.7292 - val_acc: 0.7532\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2710 - acc: 0.5664 - val_loss: 37.7239 - val_acc: 0.7532\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2644 - acc: 0.5664 - val_loss: 37.7186 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2578 - acc: 0.5664 - val_loss: 37.7133 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2512 - acc: 0.5664 - val_loss: 37.7080 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2446 - acc: 0.5664 - val_loss: 37.7027 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2379 - acc: 0.5664 - val_loss: 37.6973 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2313 - acc: 0.5664 - val_loss: 37.6920 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2247 - acc: 0.5664 - val_loss: 37.6867 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2181 - acc: 0.5664 - val_loss: 37.6814 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2115 - acc: 0.5664 - val_loss: 37.6760 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.2049 - acc: 0.5664 - val_loss: 37.6708 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1983 - acc: 0.5664 - val_loss: 37.6654 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1916 - acc: 0.5664 - val_loss: 37.6601 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1850 - acc: 0.5664 - val_loss: 37.6548 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1784 - acc: 0.5664 - val_loss: 37.6494 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1718 - acc: 0.5664 - val_loss: 37.6441 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1652 - acc: 0.5664 - val_loss: 37.6388 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1586 - acc: 0.5664 - val_loss: 37.6334 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1520 - acc: 0.5664 - val_loss: 37.6282 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1453 - acc: 0.5664 - val_loss: 37.6229 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1388 - acc: 0.5664 - val_loss: 37.6177 - val_acc: 0.7532\n",
            "saving model\n",
            "iteration  5/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1323 - acc: 0.5664 - val_loss: 37.6125 - val_acc: 0.7532\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1258 - acc: 0.5664 - val_loss: 37.6074 - val_acc: 0.7532\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1193 - acc: 0.5664 - val_loss: 37.6022 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1128 - acc: 0.5664 - val_loss: 37.5970 - val_acc: 0.7532\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.1063 - acc: 0.5664 - val_loss: 37.5918 - val_acc: 0.7532\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0998 - acc: 0.5664 - val_loss: 37.5866 - val_acc: 0.7532\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0933 - acc: 0.5664 - val_loss: 37.5814 - val_acc: 0.7532\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0868 - acc: 0.5664 - val_loss: 37.5762 - val_acc: 0.7532\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0803 - acc: 0.5664 - val_loss: 37.5710 - val_acc: 0.7532\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0737 - acc: 0.5664 - val_loss: 37.5658 - val_acc: 0.7532\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0672 - acc: 0.5664 - val_loss: 37.5606 - val_acc: 0.7532\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0607 - acc: 0.5664 - val_loss: 37.5555 - val_acc: 0.7532\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0542 - acc: 0.5664 - val_loss: 37.5502 - val_acc: 0.7532\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0477 - acc: 0.5664 - val_loss: 37.5451 - val_acc: 0.7532\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0412 - acc: 0.5664 - val_loss: 37.5399 - val_acc: 0.7532\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0347 - acc: 0.5664 - val_loss: 37.5347 - val_acc: 0.7532\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0282 - acc: 0.5664 - val_loss: 37.5295 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0216 - acc: 0.5664 - val_loss: 37.5243 - val_acc: 0.7532\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0152 - acc: 0.5664 - val_loss: 37.5192 - val_acc: 0.7532\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0088 - acc: 0.5664 - val_loss: 37.5142 - val_acc: 0.7532\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 78.0023 - acc: 0.5664 - val_loss: 37.5091 - val_acc: 0.7532\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9959 - acc: 0.5664 - val_loss: 37.5041 - val_acc: 0.7532\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9895 - acc: 0.5664 - val_loss: 37.4991 - val_acc: 0.7532\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9831 - acc: 0.5664 - val_loss: 37.4940 - val_acc: 0.7532\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9767 - acc: 0.5664 - val_loss: 37.4890 - val_acc: 0.7532\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9703 - acc: 0.5664 - val_loss: 37.4840 - val_acc: 0.7532\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9639 - acc: 0.5664 - val_loss: 37.4789 - val_acc: 0.7532\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9574 - acc: 0.5664 - val_loss: 37.4739 - val_acc: 0.7532\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9510 - acc: 0.5664 - val_loss: 37.4688 - val_acc: 0.7532\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9447 - acc: 0.5664 - val_loss: 37.4638 - val_acc: 0.7532\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9382 - acc: 0.5664 - val_loss: 37.4588 - val_acc: 0.7532\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9318 - acc: 0.5664 - val_loss: 37.4537 - val_acc: 0.7532\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9254 - acc: 0.5664 - val_loss: 37.4487 - val_acc: 0.7532\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9191 - acc: 0.5664 - val_loss: 37.4437 - val_acc: 0.7532\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9127 - acc: 0.5664 - val_loss: 37.4388 - val_acc: 0.7532\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9064 - acc: 0.5664 - val_loss: 37.4340 - val_acc: 0.7532\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.9002 - acc: 0.5664 - val_loss: 37.4291 - val_acc: 0.7532\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8939 - acc: 0.5664 - val_loss: 37.4241 - val_acc: 0.7532\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8876 - acc: 0.5664 - val_loss: 37.4193 - val_acc: 0.7532\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8813 - acc: 0.5664 - val_loss: 37.4144 - val_acc: 0.7532\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8750 - acc: 0.5664 - val_loss: 37.4095 - val_acc: 0.7532\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8687 - acc: 0.5664 - val_loss: 37.4047 - val_acc: 0.7532\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8625 - acc: 0.5664 - val_loss: 37.3998 - val_acc: 0.7532\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8562 - acc: 0.5664 - val_loss: 37.3949 - val_acc: 0.7532\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8500 - acc: 0.5664 - val_loss: 37.3900 - val_acc: 0.7532\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8436 - acc: 0.5664 - val_loss: 37.3852 - val_acc: 0.7532\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8373 - acc: 0.5664 - val_loss: 37.3803 - val_acc: 0.7532\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8311 - acc: 0.5664 - val_loss: 37.3754 - val_acc: 0.7532\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8248 - acc: 0.5664 - val_loss: 37.3705 - val_acc: 0.7532\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8185 - acc: 0.5664 - val_loss: 37.3656 - val_acc: 0.7532\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8123 - acc: 0.5664 - val_loss: 37.3608 - val_acc: 0.7532\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.8060 - acc: 0.5664 - val_loss: 37.3559 - val_acc: 0.7532\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7997 - acc: 0.5664 - val_loss: 37.3510 - val_acc: 0.7532\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7934 - acc: 0.5664 - val_loss: 37.3461 - val_acc: 0.7532\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7871 - acc: 0.5664 - val_loss: 37.3412 - val_acc: 0.7532\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7809 - acc: 0.5664 - val_loss: 37.3363 - val_acc: 0.7532\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7746 - acc: 0.5664 - val_loss: 37.3315 - val_acc: 0.7532\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7683 - acc: 0.5664 - val_loss: 37.3266 - val_acc: 0.7532\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7621 - acc: 0.5664 - val_loss: 37.3217 - val_acc: 0.7532\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7558 - acc: 0.5664 - val_loss: 37.3169 - val_acc: 0.7532\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7495 - acc: 0.5664 - val_loss: 37.3120 - val_acc: 0.7532\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7432 - acc: 0.5664 - val_loss: 37.3071 - val_acc: 0.7532\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7369 - acc: 0.5664 - val_loss: 37.3022 - val_acc: 0.7532\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7307 - acc: 0.5664 - val_loss: 37.2974 - val_acc: 0.7532\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7244 - acc: 0.5664 - val_loss: 37.2925 - val_acc: 0.7532\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7181 - acc: 0.5664 - val_loss: 37.2876 - val_acc: 0.7532\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7118 - acc: 0.5664 - val_loss: 37.2827 - val_acc: 0.7532\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.7055 - acc: 0.5664 - val_loss: 37.2778 - val_acc: 0.7532\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6993 - acc: 0.5664 - val_loss: 37.2729 - val_acc: 0.7532\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6930 - acc: 0.5664 - val_loss: 37.2681 - val_acc: 0.7532\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6867 - acc: 0.5664 - val_loss: 37.2632 - val_acc: 0.7532\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6804 - acc: 0.5664 - val_loss: 37.2583 - val_acc: 0.7532\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6742 - acc: 0.5664 - val_loss: 37.2534 - val_acc: 0.7532\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6679 - acc: 0.5664 - val_loss: 37.2485 - val_acc: 0.7532\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6617 - acc: 0.5664 - val_loss: 37.2436 - val_acc: 0.7532\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6553 - acc: 0.5664 - val_loss: 37.2388 - val_acc: 0.7532\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6491 - acc: 0.5664 - val_loss: 37.2339 - val_acc: 0.7532\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6428 - acc: 0.5664 - val_loss: 37.2290 - val_acc: 0.7532\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6365 - acc: 0.5664 - val_loss: 37.2241 - val_acc: 0.7532\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6302 - acc: 0.5664 - val_loss: 37.2192 - val_acc: 0.7532\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6240 - acc: 0.5664 - val_loss: 37.2143 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6177 - acc: 0.5664 - val_loss: 37.2095 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6114 - acc: 0.5664 - val_loss: 37.2047 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.6052 - acc: 0.5664 - val_loss: 37.1999 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5990 - acc: 0.5664 - val_loss: 37.1952 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5928 - acc: 0.5664 - val_loss: 37.1904 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5866 - acc: 0.5664 - val_loss: 37.1857 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5805 - acc: 0.5664 - val_loss: 37.1809 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5743 - acc: 0.5664 - val_loss: 37.1761 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5681 - acc: 0.5664 - val_loss: 37.1714 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5619 - acc: 0.5664 - val_loss: 37.1666 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5557 - acc: 0.5664 - val_loss: 37.1618 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5496 - acc: 0.5664 - val_loss: 37.1571 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5434 - acc: 0.5664 - val_loss: 37.1523 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5372 - acc: 0.5664 - val_loss: 37.1476 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5310 - acc: 0.5664 - val_loss: 37.1427 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5248 - acc: 0.5664 - val_loss: 37.1380 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5186 - acc: 0.5664 - val_loss: 37.1332 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5124 - acc: 0.5664 - val_loss: 37.1285 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5062 - acc: 0.5664 - val_loss: 37.1237 - val_acc: 0.7532\n",
            "saving model\n",
            "iteration  6/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.5001 - acc: 0.5664 - val_loss: 37.1190 - val_acc: 0.7532\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4939 - acc: 0.5664 - val_loss: 37.1142 - val_acc: 0.7532\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4877 - acc: 0.5664 - val_loss: 37.1095 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4815 - acc: 0.5664 - val_loss: 37.1047 - val_acc: 0.7532\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4753 - acc: 0.5664 - val_loss: 37.1000 - val_acc: 0.7532\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4692 - acc: 0.5664 - val_loss: 37.0952 - val_acc: 0.7532\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4630 - acc: 0.5664 - val_loss: 37.0904 - val_acc: 0.7532\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4568 - acc: 0.5664 - val_loss: 37.0857 - val_acc: 0.7532\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4506 - acc: 0.5664 - val_loss: 37.0810 - val_acc: 0.7532\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4445 - acc: 0.5664 - val_loss: 37.0764 - val_acc: 0.7532\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4384 - acc: 0.5664 - val_loss: 37.0718 - val_acc: 0.7532\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4324 - acc: 0.5664 - val_loss: 37.0671 - val_acc: 0.7532\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4263 - acc: 0.5664 - val_loss: 37.0625 - val_acc: 0.7532\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4202 - acc: 0.5664 - val_loss: 37.0579 - val_acc: 0.7532\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4141 - acc: 0.5664 - val_loss: 37.0533 - val_acc: 0.7532\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4080 - acc: 0.5664 - val_loss: 37.0487 - val_acc: 0.7532\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.4019 - acc: 0.5664 - val_loss: 37.0441 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3958 - acc: 0.5664 - val_loss: 37.0395 - val_acc: 0.7532\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3897 - acc: 0.5664 - val_loss: 37.0349 - val_acc: 0.7532\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3837 - acc: 0.5664 - val_loss: 37.0302 - val_acc: 0.7532\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3775 - acc: 0.5664 - val_loss: 37.0256 - val_acc: 0.7532\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3715 - acc: 0.5664 - val_loss: 37.0210 - val_acc: 0.7532\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3654 - acc: 0.5664 - val_loss: 37.0164 - val_acc: 0.7532\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3593 - acc: 0.5664 - val_loss: 37.0118 - val_acc: 0.7532\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3533 - acc: 0.5664 - val_loss: 37.0072 - val_acc: 0.7532\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3472 - acc: 0.5664 - val_loss: 37.0026 - val_acc: 0.7532\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3411 - acc: 0.5664 - val_loss: 36.9980 - val_acc: 0.7532\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3351 - acc: 0.5664 - val_loss: 36.9934 - val_acc: 0.7532\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3290 - acc: 0.5664 - val_loss: 36.9888 - val_acc: 0.7532\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3230 - acc: 0.5664 - val_loss: 36.9844 - val_acc: 0.7532\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3170 - acc: 0.5664 - val_loss: 36.9799 - val_acc: 0.7532\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3111 - acc: 0.5664 - val_loss: 36.9754 - val_acc: 0.7532\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.3051 - acc: 0.5664 - val_loss: 36.9709 - val_acc: 0.7532\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2991 - acc: 0.5664 - val_loss: 36.9665 - val_acc: 0.7532\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2932 - acc: 0.5664 - val_loss: 36.9620 - val_acc: 0.7532\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2872 - acc: 0.5664 - val_loss: 36.9576 - val_acc: 0.7532\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2812 - acc: 0.5664 - val_loss: 36.9531 - val_acc: 0.7532\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2753 - acc: 0.5664 - val_loss: 36.9487 - val_acc: 0.7532\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2693 - acc: 0.5664 - val_loss: 36.9442 - val_acc: 0.7532\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2634 - acc: 0.5664 - val_loss: 36.9397 - val_acc: 0.7532\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2574 - acc: 0.5664 - val_loss: 36.9352 - val_acc: 0.7532\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2514 - acc: 0.5664 - val_loss: 36.9308 - val_acc: 0.7532\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2455 - acc: 0.5664 - val_loss: 36.9263 - val_acc: 0.7532\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2395 - acc: 0.5664 - val_loss: 36.9218 - val_acc: 0.7532\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2335 - acc: 0.5664 - val_loss: 36.9174 - val_acc: 0.7532\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2277 - acc: 0.5664 - val_loss: 36.9129 - val_acc: 0.7532\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2216 - acc: 0.5664 - val_loss: 36.9083 - val_acc: 0.7532\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2157 - acc: 0.5664 - val_loss: 36.9039 - val_acc: 0.7532\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2097 - acc: 0.5664 - val_loss: 36.8994 - val_acc: 0.7532\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.2037 - acc: 0.5664 - val_loss: 36.8950 - val_acc: 0.7532\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1977 - acc: 0.5664 - val_loss: 36.8905 - val_acc: 0.7532\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1918 - acc: 0.5664 - val_loss: 36.8861 - val_acc: 0.7532\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1858 - acc: 0.5664 - val_loss: 36.8816 - val_acc: 0.7532\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1799 - acc: 0.5664 - val_loss: 36.8771 - val_acc: 0.7532\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1739 - acc: 0.5664 - val_loss: 36.8726 - val_acc: 0.7532\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1679 - acc: 0.5664 - val_loss: 36.8681 - val_acc: 0.7532\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1620 - acc: 0.5664 - val_loss: 36.8636 - val_acc: 0.7532\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1560 - acc: 0.5664 - val_loss: 36.8591 - val_acc: 0.7532\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1500 - acc: 0.5664 - val_loss: 36.8547 - val_acc: 0.7532\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1441 - acc: 0.5664 - val_loss: 36.8502 - val_acc: 0.7532\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1381 - acc: 0.5664 - val_loss: 36.8457 - val_acc: 0.7532\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1321 - acc: 0.5664 - val_loss: 36.8412 - val_acc: 0.7532\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1262 - acc: 0.5664 - val_loss: 36.8368 - val_acc: 0.7532\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1202 - acc: 0.5664 - val_loss: 36.8323 - val_acc: 0.7532\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1142 - acc: 0.5664 - val_loss: 36.8278 - val_acc: 0.7532\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1083 - acc: 0.5664 - val_loss: 36.8234 - val_acc: 0.7532\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.1023 - acc: 0.5664 - val_loss: 36.8189 - val_acc: 0.7532\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0964 - acc: 0.5664 - val_loss: 36.8144 - val_acc: 0.7532\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0904 - acc: 0.5664 - val_loss: 36.8100 - val_acc: 0.7532\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0846 - acc: 0.5664 - val_loss: 36.8057 - val_acc: 0.7532\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0787 - acc: 0.5664 - val_loss: 36.8013 - val_acc: 0.7532\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0728 - acc: 0.5664 - val_loss: 36.7970 - val_acc: 0.7532\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0669 - acc: 0.5664 - val_loss: 36.7926 - val_acc: 0.7532\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0611 - acc: 0.5664 - val_loss: 36.7883 - val_acc: 0.7532\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0552 - acc: 0.5664 - val_loss: 36.7839 - val_acc: 0.7532\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0493 - acc: 0.5664 - val_loss: 36.7795 - val_acc: 0.7532\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0435 - acc: 0.5664 - val_loss: 36.7752 - val_acc: 0.7532\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0376 - acc: 0.5664 - val_loss: 36.7708 - val_acc: 0.7532\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0318 - acc: 0.5664 - val_loss: 36.7665 - val_acc: 0.7532\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0258 - acc: 0.5664 - val_loss: 36.7621 - val_acc: 0.7532\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0200 - acc: 0.5664 - val_loss: 36.7578 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0141 - acc: 0.5664 - val_loss: 36.7534 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0082 - acc: 0.5664 - val_loss: 36.7491 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 77.0024 - acc: 0.5664 - val_loss: 36.7447 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9965 - acc: 0.5664 - val_loss: 36.7404 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9907 - acc: 0.5664 - val_loss: 36.7360 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9848 - acc: 0.5664 - val_loss: 36.7316 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9789 - acc: 0.5664 - val_loss: 36.7273 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9731 - acc: 0.5664 - val_loss: 36.7229 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9672 - acc: 0.5664 - val_loss: 36.7186 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9613 - acc: 0.5664 - val_loss: 36.7143 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9555 - acc: 0.5664 - val_loss: 36.7099 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9496 - acc: 0.5664 - val_loss: 36.7055 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9437 - acc: 0.5664 - val_loss: 36.7012 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9379 - acc: 0.5664 - val_loss: 36.6968 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9320 - acc: 0.5664 - val_loss: 36.6925 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9261 - acc: 0.5664 - val_loss: 36.6881 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9203 - acc: 0.5664 - val_loss: 36.6838 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9144 - acc: 0.5664 - val_loss: 36.6794 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9086 - acc: 0.5664 - val_loss: 36.6750 - val_acc: 0.7532\n",
            "saving model\n",
            "iteration  7/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.9027 - acc: 0.5664 - val_loss: 36.6707 - val_acc: 0.7532\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8969 - acc: 0.5664 - val_loss: 36.6665 - val_acc: 0.7532\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8911 - acc: 0.5664 - val_loss: 36.6623 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8854 - acc: 0.5664 - val_loss: 36.6581 - val_acc: 0.7532\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8796 - acc: 0.5664 - val_loss: 36.6538 - val_acc: 0.7532\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8738 - acc: 0.5664 - val_loss: 36.6496 - val_acc: 0.7532\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8680 - acc: 0.5664 - val_loss: 36.6454 - val_acc: 0.7532\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8623 - acc: 0.5664 - val_loss: 36.6412 - val_acc: 0.7532\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8565 - acc: 0.5664 - val_loss: 36.6370 - val_acc: 0.7532\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8508 - acc: 0.5664 - val_loss: 36.6328 - val_acc: 0.7532\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8450 - acc: 0.5664 - val_loss: 36.6286 - val_acc: 0.7532\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8393 - acc: 0.5664 - val_loss: 36.6244 - val_acc: 0.7532\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8335 - acc: 0.5664 - val_loss: 36.6202 - val_acc: 0.7532\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8277 - acc: 0.5664 - val_loss: 36.6160 - val_acc: 0.7532\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8220 - acc: 0.5664 - val_loss: 36.6117 - val_acc: 0.7532\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8163 - acc: 0.5664 - val_loss: 36.6076 - val_acc: 0.7532\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8104 - acc: 0.5664 - val_loss: 36.6033 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.8047 - acc: 0.5664 - val_loss: 36.5991 - val_acc: 0.7532\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7990 - acc: 0.5664 - val_loss: 36.5949 - val_acc: 0.7532\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7932 - acc: 0.5664 - val_loss: 36.5907 - val_acc: 0.7532\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7874 - acc: 0.5664 - val_loss: 36.5866 - val_acc: 0.7532\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7817 - acc: 0.5664 - val_loss: 36.5823 - val_acc: 0.7532\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7759 - acc: 0.5664 - val_loss: 36.5781 - val_acc: 0.7532\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7701 - acc: 0.5664 - val_loss: 36.5739 - val_acc: 0.7532\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7644 - acc: 0.5664 - val_loss: 36.5697 - val_acc: 0.7532\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7586 - acc: 0.5664 - val_loss: 36.5655 - val_acc: 0.7532\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7529 - acc: 0.5664 - val_loss: 36.5613 - val_acc: 0.7532\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7472 - acc: 0.5664 - val_loss: 36.5572 - val_acc: 0.7532\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7415 - acc: 0.5664 - val_loss: 36.5531 - val_acc: 0.7532\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7359 - acc: 0.5664 - val_loss: 36.5490 - val_acc: 0.7532\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7302 - acc: 0.5664 - val_loss: 36.5449 - val_acc: 0.7532\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7246 - acc: 0.5664 - val_loss: 36.5408 - val_acc: 0.7532\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7189 - acc: 0.5664 - val_loss: 36.5367 - val_acc: 0.7532\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7132 - acc: 0.5664 - val_loss: 36.5326 - val_acc: 0.7532\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7076 - acc: 0.5664 - val_loss: 36.5285 - val_acc: 0.7532\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.7019 - acc: 0.5664 - val_loss: 36.5245 - val_acc: 0.7532\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6962 - acc: 0.5664 - val_loss: 36.5204 - val_acc: 0.7532\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6906 - acc: 0.5664 - val_loss: 36.5163 - val_acc: 0.7532\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6849 - acc: 0.5664 - val_loss: 36.5122 - val_acc: 0.7532\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6793 - acc: 0.5664 - val_loss: 36.5081 - val_acc: 0.7532\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6736 - acc: 0.5664 - val_loss: 36.5040 - val_acc: 0.7532\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6680 - acc: 0.5664 - val_loss: 36.4999 - val_acc: 0.7532\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6623 - acc: 0.5664 - val_loss: 36.4958 - val_acc: 0.7532\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6567 - acc: 0.5664 - val_loss: 36.4917 - val_acc: 0.7532\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6510 - acc: 0.5664 - val_loss: 36.4876 - val_acc: 0.7532\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6453 - acc: 0.5664 - val_loss: 36.4835 - val_acc: 0.7532\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6397 - acc: 0.5664 - val_loss: 36.4794 - val_acc: 0.7532\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6340 - acc: 0.5664 - val_loss: 36.4753 - val_acc: 0.7532\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6283 - acc: 0.5664 - val_loss: 36.4712 - val_acc: 0.7532\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6227 - acc: 0.5664 - val_loss: 36.4671 - val_acc: 0.7532\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6170 - acc: 0.5664 - val_loss: 36.4630 - val_acc: 0.7532\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6114 - acc: 0.5664 - val_loss: 36.4589 - val_acc: 0.7532\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6057 - acc: 0.5664 - val_loss: 36.4548 - val_acc: 0.7532\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.6000 - acc: 0.5664 - val_loss: 36.4507 - val_acc: 0.7532\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5944 - acc: 0.5664 - val_loss: 36.4466 - val_acc: 0.7532\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5887 - acc: 0.5664 - val_loss: 36.4425 - val_acc: 0.7532\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5831 - acc: 0.5664 - val_loss: 36.4385 - val_acc: 0.7532\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5775 - acc: 0.5664 - val_loss: 36.4346 - val_acc: 0.7532\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5720 - acc: 0.5664 - val_loss: 36.4306 - val_acc: 0.7532\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5664 - acc: 0.5664 - val_loss: 36.4266 - val_acc: 0.7532\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5608 - acc: 0.5664 - val_loss: 36.4226 - val_acc: 0.7532\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5552 - acc: 0.5664 - val_loss: 36.4186 - val_acc: 0.7532\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5496 - acc: 0.5664 - val_loss: 36.4146 - val_acc: 0.7532\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5441 - acc: 0.5664 - val_loss: 36.4106 - val_acc: 0.7532\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5385 - acc: 0.5664 - val_loss: 36.4067 - val_acc: 0.7532\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5329 - acc: 0.5664 - val_loss: 36.4027 - val_acc: 0.7532\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5274 - acc: 0.5664 - val_loss: 36.3987 - val_acc: 0.7532\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5217 - acc: 0.5664 - val_loss: 36.3946 - val_acc: 0.7532\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5162 - acc: 0.5664 - val_loss: 36.3907 - val_acc: 0.7532\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5106 - acc: 0.5664 - val_loss: 36.3867 - val_acc: 0.7532\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.5050 - acc: 0.5664 - val_loss: 36.3827 - val_acc: 0.7532\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4995 - acc: 0.5664 - val_loss: 36.3787 - val_acc: 0.7532\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4939 - acc: 0.5664 - val_loss: 36.3747 - val_acc: 0.7532\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4883 - acc: 0.5664 - val_loss: 36.3707 - val_acc: 0.7532\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4827 - acc: 0.5664 - val_loss: 36.3667 - val_acc: 0.7532\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4771 - acc: 0.5664 - val_loss: 36.3627 - val_acc: 0.7532\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4715 - acc: 0.5664 - val_loss: 36.3587 - val_acc: 0.7532\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4659 - acc: 0.5664 - val_loss: 36.3547 - val_acc: 0.7532\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4604 - acc: 0.5664 - val_loss: 36.3507 - val_acc: 0.7532\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4548 - acc: 0.5664 - val_loss: 36.3467 - val_acc: 0.7532\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4492 - acc: 0.5664 - val_loss: 36.3427 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4436 - acc: 0.5664 - val_loss: 36.3387 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4380 - acc: 0.5664 - val_loss: 36.3347 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4325 - acc: 0.5664 - val_loss: 36.3307 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4269 - acc: 0.5664 - val_loss: 36.3267 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4213 - acc: 0.5664 - val_loss: 36.3227 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4157 - acc: 0.5664 - val_loss: 36.3187 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4101 - acc: 0.5664 - val_loss: 36.3147 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.4046 - acc: 0.5664 - val_loss: 36.3107 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3990 - acc: 0.5664 - val_loss: 36.3067 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3934 - acc: 0.5664 - val_loss: 36.3027 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3878 - acc: 0.5664 - val_loss: 36.2986 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3823 - acc: 0.5664 - val_loss: 36.2946 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3766 - acc: 0.5664 - val_loss: 36.2906 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3711 - acc: 0.5664 - val_loss: 36.2867 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3655 - acc: 0.5664 - val_loss: 36.2827 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3599 - acc: 0.5664 - val_loss: 36.2788 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3545 - acc: 0.5664 - val_loss: 36.2749 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3490 - acc: 0.5664 - val_loss: 36.2711 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3435 - acc: 0.5664 - val_loss: 36.2672 - val_acc: 0.7532\n",
            "saving model\n",
            "iteration  8/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3380 - acc: 0.5664 - val_loss: 36.2633 - val_acc: 0.7532\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3325 - acc: 0.5664 - val_loss: 36.2595 - val_acc: 0.7532\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3270 - acc: 0.5664 - val_loss: 36.2556 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3215 - acc: 0.5664 - val_loss: 36.2518 - val_acc: 0.7532\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3160 - acc: 0.5664 - val_loss: 36.2479 - val_acc: 0.7532\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3105 - acc: 0.5664 - val_loss: 36.2440 - val_acc: 0.7532\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.3050 - acc: 0.5664 - val_loss: 36.2402 - val_acc: 0.7532\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2996 - acc: 0.5664 - val_loss: 36.2363 - val_acc: 0.7532\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2940 - acc: 0.5664 - val_loss: 36.2324 - val_acc: 0.7532\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2886 - acc: 0.5664 - val_loss: 36.2285 - val_acc: 0.7532\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2831 - acc: 0.5664 - val_loss: 36.2247 - val_acc: 0.7532\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2776 - acc: 0.5664 - val_loss: 36.2208 - val_acc: 0.7532\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2721 - acc: 0.5664 - val_loss: 36.2170 - val_acc: 0.7532\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2667 - acc: 0.5664 - val_loss: 36.2131 - val_acc: 0.7532\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2612 - acc: 0.5664 - val_loss: 36.2093 - val_acc: 0.7532\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2557 - acc: 0.5664 - val_loss: 36.2054 - val_acc: 0.7532\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2502 - acc: 0.5664 - val_loss: 36.2016 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2447 - acc: 0.5664 - val_loss: 36.1977 - val_acc: 0.7532\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2392 - acc: 0.5664 - val_loss: 36.1938 - val_acc: 0.7532\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2337 - acc: 0.5664 - val_loss: 36.1900 - val_acc: 0.7532\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2283 - acc: 0.5664 - val_loss: 36.1861 - val_acc: 0.7532\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2228 - acc: 0.5664 - val_loss: 36.1822 - val_acc: 0.7532\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2173 - acc: 0.5664 - val_loss: 36.1783 - val_acc: 0.7532\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2118 - acc: 0.5664 - val_loss: 36.1745 - val_acc: 0.7532\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2063 - acc: 0.5664 - val_loss: 36.1706 - val_acc: 0.7532\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.2008 - acc: 0.5664 - val_loss: 36.1667 - val_acc: 0.7532\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1954 - acc: 0.5664 - val_loss: 36.1629 - val_acc: 0.7532\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1898 - acc: 0.5664 - val_loss: 36.1590 - val_acc: 0.7532\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1844 - acc: 0.5664 - val_loss: 36.1552 - val_acc: 0.7532\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1789 - acc: 0.5664 - val_loss: 36.1514 - val_acc: 0.7532\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1735 - acc: 0.5664 - val_loss: 36.1477 - val_acc: 0.7532\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1682 - acc: 0.5664 - val_loss: 36.1439 - val_acc: 0.7532\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1628 - acc: 0.5664 - val_loss: 36.1402 - val_acc: 0.7532\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1574 - acc: 0.5664 - val_loss: 36.1364 - val_acc: 0.7532\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1520 - acc: 0.5664 - val_loss: 36.1326 - val_acc: 0.7532\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1466 - acc: 0.5664 - val_loss: 36.1289 - val_acc: 0.7532\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1411 - acc: 0.5664 - val_loss: 36.1251 - val_acc: 0.7532\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1358 - acc: 0.5664 - val_loss: 36.1213 - val_acc: 0.7532\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1303 - acc: 0.5664 - val_loss: 36.1176 - val_acc: 0.7532\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1249 - acc: 0.5664 - val_loss: 36.1138 - val_acc: 0.7532\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1196 - acc: 0.5664 - val_loss: 36.1100 - val_acc: 0.7532\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1142 - acc: 0.5664 - val_loss: 36.1062 - val_acc: 0.7532\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1088 - acc: 0.5664 - val_loss: 36.1025 - val_acc: 0.7532\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.1034 - acc: 0.5664 - val_loss: 36.0987 - val_acc: 0.7532\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0980 - acc: 0.5664 - val_loss: 36.0949 - val_acc: 0.7532\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0925 - acc: 0.5664 - val_loss: 36.0912 - val_acc: 0.7532\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0872 - acc: 0.5664 - val_loss: 36.0875 - val_acc: 0.7532\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0819 - acc: 0.5664 - val_loss: 36.0839 - val_acc: 0.7532\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0765 - acc: 0.5664 - val_loss: 36.0802 - val_acc: 0.7532\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0713 - acc: 0.5664 - val_loss: 36.0765 - val_acc: 0.7532\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0659 - acc: 0.5664 - val_loss: 36.0729 - val_acc: 0.7532\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0606 - acc: 0.5664 - val_loss: 36.0692 - val_acc: 0.7532\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0552 - acc: 0.5664 - val_loss: 36.0655 - val_acc: 0.7532\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0499 - acc: 0.5664 - val_loss: 36.0618 - val_acc: 0.7532\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0446 - acc: 0.5664 - val_loss: 36.0581 - val_acc: 0.7532\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0393 - acc: 0.5664 - val_loss: 36.0545 - val_acc: 0.7532\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0339 - acc: 0.5664 - val_loss: 36.0508 - val_acc: 0.7532\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0286 - acc: 0.5664 - val_loss: 36.0471 - val_acc: 0.7532\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0233 - acc: 0.5664 - val_loss: 36.0434 - val_acc: 0.7532\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0179 - acc: 0.5664 - val_loss: 36.0398 - val_acc: 0.7532\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0126 - acc: 0.5664 - val_loss: 36.0361 - val_acc: 0.7532\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0073 - acc: 0.5664 - val_loss: 36.0324 - val_acc: 0.7532\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 76.0019 - acc: 0.5664 - val_loss: 36.0287 - val_acc: 0.7532\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9966 - acc: 0.5664 - val_loss: 36.0250 - val_acc: 0.7532\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9913 - acc: 0.5664 - val_loss: 36.0213 - val_acc: 0.7532\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9859 - acc: 0.5664 - val_loss: 36.0177 - val_acc: 0.7532\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9806 - acc: 0.5664 - val_loss: 36.0140 - val_acc: 0.7532\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9753 - acc: 0.5664 - val_loss: 36.0103 - val_acc: 0.7532\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9700 - acc: 0.5664 - val_loss: 36.0066 - val_acc: 0.7532\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9646 - acc: 0.5664 - val_loss: 36.0030 - val_acc: 0.7532\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9593 - acc: 0.5664 - val_loss: 35.9992 - val_acc: 0.7532\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9540 - acc: 0.5664 - val_loss: 35.9956 - val_acc: 0.7532\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9487 - acc: 0.5664 - val_loss: 35.9919 - val_acc: 0.7532\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9434 - acc: 0.5664 - val_loss: 35.9882 - val_acc: 0.7532\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9380 - acc: 0.5664 - val_loss: 35.9845 - val_acc: 0.7532\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9327 - acc: 0.5664 - val_loss: 35.9809 - val_acc: 0.7532\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9274 - acc: 0.5664 - val_loss: 35.9772 - val_acc: 0.7532\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9221 - acc: 0.5664 - val_loss: 35.9735 - val_acc: 0.7532\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9167 - acc: 0.5664 - val_loss: 35.9698 - val_acc: 0.7532\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9114 - acc: 0.5664 - val_loss: 35.9662 - val_acc: 0.7532\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9061 - acc: 0.5664 - val_loss: 35.9625 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.9008 - acc: 0.5664 - val_loss: 35.9588 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8955 - acc: 0.5664 - val_loss: 35.9552 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8901 - acc: 0.5664 - val_loss: 35.9515 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8848 - acc: 0.5664 - val_loss: 35.9478 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8795 - acc: 0.5664 - val_loss: 35.9441 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8742 - acc: 0.5664 - val_loss: 35.9405 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8689 - acc: 0.5664 - val_loss: 35.9368 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8635 - acc: 0.5664 - val_loss: 35.9331 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8582 - acc: 0.5664 - val_loss: 35.9294 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8529 - acc: 0.5664 - val_loss: 35.9257 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8476 - acc: 0.5664 - val_loss: 35.9220 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8423 - acc: 0.5664 - val_loss: 35.9183 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8369 - acc: 0.5664 - val_loss: 35.9147 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8317 - acc: 0.5664 - val_loss: 35.9112 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8264 - acc: 0.5664 - val_loss: 35.9076 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8212 - acc: 0.5664 - val_loss: 35.9040 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8159 - acc: 0.5664 - val_loss: 35.9005 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8107 - acc: 0.5664 - val_loss: 35.8969 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8055 - acc: 0.5664 - val_loss: 35.8934 - val_acc: 0.7532\n",
            "saving model\n",
            "iteration  9/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.8002 - acc: 0.5664 - val_loss: 35.8898 - val_acc: 0.7532\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7949 - acc: 0.5664 - val_loss: 35.8863 - val_acc: 0.7532\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7897 - acc: 0.5664 - val_loss: 35.8827 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7845 - acc: 0.5664 - val_loss: 35.8791 - val_acc: 0.7532\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7793 - acc: 0.5664 - val_loss: 35.8756 - val_acc: 0.7532\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7740 - acc: 0.5664 - val_loss: 35.8720 - val_acc: 0.7532\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7688 - acc: 0.5664 - val_loss: 35.8684 - val_acc: 0.7532\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7635 - acc: 0.5664 - val_loss: 35.8648 - val_acc: 0.7532\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7583 - acc: 0.5664 - val_loss: 35.8612 - val_acc: 0.7532\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7530 - acc: 0.5664 - val_loss: 35.8577 - val_acc: 0.7532\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7477 - acc: 0.5664 - val_loss: 35.8541 - val_acc: 0.7532\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7425 - acc: 0.5664 - val_loss: 35.8505 - val_acc: 0.7532\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7372 - acc: 0.5664 - val_loss: 35.8469 - val_acc: 0.7532\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7320 - acc: 0.5664 - val_loss: 35.8433 - val_acc: 0.7532\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7267 - acc: 0.5664 - val_loss: 35.8398 - val_acc: 0.7532\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7214 - acc: 0.5664 - val_loss: 35.8362 - val_acc: 0.7532\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7162 - acc: 0.5664 - val_loss: 35.8326 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7109 - acc: 0.5664 - val_loss: 35.8290 - val_acc: 0.7532\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7057 - acc: 0.5664 - val_loss: 35.8254 - val_acc: 0.7532\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.7004 - acc: 0.5664 - val_loss: 35.8218 - val_acc: 0.7532\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6952 - acc: 0.5664 - val_loss: 35.8183 - val_acc: 0.7532\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6899 - acc: 0.5664 - val_loss: 35.8147 - val_acc: 0.7532\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6847 - acc: 0.5664 - val_loss: 35.8111 - val_acc: 0.7532\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6794 - acc: 0.5664 - val_loss: 35.8075 - val_acc: 0.7532\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6742 - acc: 0.5664 - val_loss: 35.8040 - val_acc: 0.7532\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6690 - acc: 0.5664 - val_loss: 35.8004 - val_acc: 0.7532\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6637 - acc: 0.5664 - val_loss: 35.7967 - val_acc: 0.7532\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6584 - acc: 0.5664 - val_loss: 35.7932 - val_acc: 0.7532\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6532 - acc: 0.5664 - val_loss: 35.7896 - val_acc: 0.7532\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6479 - acc: 0.5664 - val_loss: 35.7860 - val_acc: 0.7532\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6426 - acc: 0.5664 - val_loss: 35.7824 - val_acc: 0.7532\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6374 - acc: 0.5664 - val_loss: 35.7788 - val_acc: 0.7532\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6321 - acc: 0.5664 - val_loss: 35.7752 - val_acc: 0.7532\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6269 - acc: 0.5664 - val_loss: 35.7717 - val_acc: 0.7532\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6217 - acc: 0.5664 - val_loss: 35.7682 - val_acc: 0.7532\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6166 - acc: 0.5664 - val_loss: 35.7648 - val_acc: 0.7532\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6113 - acc: 0.5664 - val_loss: 35.7612 - val_acc: 0.7532\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6062 - acc: 0.5664 - val_loss: 35.7578 - val_acc: 0.7532\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6010 - acc: 0.5664 - val_loss: 35.7544 - val_acc: 0.7532\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5959 - acc: 0.5664 - val_loss: 35.7510 - val_acc: 0.7532\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5908 - acc: 0.5664 - val_loss: 35.7476 - val_acc: 0.7532\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5857 - acc: 0.5664 - val_loss: 35.7442 - val_acc: 0.7532\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5806 - acc: 0.5664 - val_loss: 35.7408 - val_acc: 0.7532\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5755 - acc: 0.5664 - val_loss: 35.7374 - val_acc: 0.7532\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5704 - acc: 0.5664 - val_loss: 35.7340 - val_acc: 0.7532\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5652 - acc: 0.5664 - val_loss: 35.7305 - val_acc: 0.7532\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5601 - acc: 0.5664 - val_loss: 35.7272 - val_acc: 0.7532\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5550 - acc: 0.5664 - val_loss: 35.7238 - val_acc: 0.7532\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5499 - acc: 0.5664 - val_loss: 35.7204 - val_acc: 0.7532\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5448 - acc: 0.5664 - val_loss: 35.7170 - val_acc: 0.7532\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5396 - acc: 0.5663 - val_loss: 35.7136 - val_acc: 0.7532\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5345 - acc: 0.5663 - val_loss: 35.7101 - val_acc: 0.7532\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5294 - acc: 0.5663 - val_loss: 35.7067 - val_acc: 0.7532\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5243 - acc: 0.5663 - val_loss: 35.7033 - val_acc: 0.7532\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5191 - acc: 0.5663 - val_loss: 35.6999 - val_acc: 0.7532\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5140 - acc: 0.5663 - val_loss: 35.6964 - val_acc: 0.7532\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5089 - acc: 0.5663 - val_loss: 35.6929 - val_acc: 0.7532\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5037 - acc: 0.5663 - val_loss: 35.6894 - val_acc: 0.7532\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4985 - acc: 0.5663 - val_loss: 35.6859 - val_acc: 0.7532\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4933 - acc: 0.5663 - val_loss: 35.6824 - val_acc: 0.7532\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4881 - acc: 0.5663 - val_loss: 35.6788 - val_acc: 0.7532\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4828 - acc: 0.5663 - val_loss: 35.6752 - val_acc: 0.7532\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4776 - acc: 0.5663 - val_loss: 35.6717 - val_acc: 0.7532\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4723 - acc: 0.5663 - val_loss: 35.6681 - val_acc: 0.7532\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4671 - acc: 0.5663 - val_loss: 35.6645 - val_acc: 0.7532\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4618 - acc: 0.5663 - val_loss: 35.6609 - val_acc: 0.7532\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4565 - acc: 0.5663 - val_loss: 35.6573 - val_acc: 0.7532\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4512 - acc: 0.5663 - val_loss: 35.6538 - val_acc: 0.7532\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4458 - acc: 0.5663 - val_loss: 35.6502 - val_acc: 0.7532\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4405 - acc: 0.5663 - val_loss: 35.6466 - val_acc: 0.7532\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4350 - acc: 0.5663 - val_loss: 35.6430 - val_acc: 0.7532\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4295 - acc: 0.5663 - val_loss: 35.6394 - val_acc: 0.7532\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4240 - acc: 0.5663 - val_loss: 35.6357 - val_acc: 0.7531\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4184 - acc: 0.5663 - val_loss: 35.6320 - val_acc: 0.7531\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4124 - acc: 0.5663 - val_loss: 35.6282 - val_acc: 0.7531\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4054 - acc: 0.5662 - val_loss: 35.6235 - val_acc: 0.7531\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3911 - acc: 0.5662 - val_loss: 35.6180 - val_acc: 0.7529\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3701 - acc: 0.5661 - val_loss: 35.6140 - val_acc: 0.7526\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3474 - acc: 0.5659 - val_loss: 35.6112 - val_acc: 0.7522\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3175 - acc: 0.5656 - val_loss: 35.6254 - val_acc: 0.7511\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 222.3348 - acc: 0.5647 - val_loss: 36.1643 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6385 - acc: 0.5664 - val_loss: 36.1616 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6338 - acc: 0.5664 - val_loss: 36.1589 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6291 - acc: 0.5664 - val_loss: 36.1563 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6243 - acc: 0.5664 - val_loss: 36.1536 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6196 - acc: 0.5664 - val_loss: 36.1509 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6149 - acc: 0.5664 - val_loss: 36.1482 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6102 - acc: 0.5664 - val_loss: 36.1455 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6054 - acc: 0.5664 - val_loss: 36.1428 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.6007 - acc: 0.5664 - val_loss: 36.1401 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5959 - acc: 0.5664 - val_loss: 36.1374 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5912 - acc: 0.5664 - val_loss: 36.1347 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5865 - acc: 0.5664 - val_loss: 36.1320 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5818 - acc: 0.5664 - val_loss: 36.1294 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5770 - acc: 0.5664 - val_loss: 36.1267 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5724 - acc: 0.5664 - val_loss: 36.1242 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5677 - acc: 0.5664 - val_loss: 36.1216 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5630 - acc: 0.5664 - val_loss: 36.1190 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5584 - acc: 0.5664 - val_loss: 36.1164 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5538 - acc: 0.5664 - val_loss: 36.1139 - val_acc: 0.7532\n",
            "saving model\n",
            "iteration 10/1000\n",
            "Train on 760 samples, validate on 40 samples\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5491 - acc: 0.5664 - val_loss: 36.1113 - val_acc: 0.7532\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5445 - acc: 0.5664 - val_loss: 36.1088 - val_acc: 0.7532\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5398 - acc: 0.5664 - val_loss: 36.1062 - val_acc: 0.7532\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5352 - acc: 0.5664 - val_loss: 36.1036 - val_acc: 0.7532\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5305 - acc: 0.5664 - val_loss: 36.1010 - val_acc: 0.7532\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5258 - acc: 0.5664 - val_loss: 36.0985 - val_acc: 0.7532\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5212 - acc: 0.5664 - val_loss: 36.0959 - val_acc: 0.7532\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5166 - acc: 0.5664 - val_loss: 36.0933 - val_acc: 0.7532\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5119 - acc: 0.5664 - val_loss: 36.0908 - val_acc: 0.7532\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5072 - acc: 0.5664 - val_loss: 36.0882 - val_acc: 0.7532\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.5025 - acc: 0.5664 - val_loss: 36.0856 - val_acc: 0.7532\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4979 - acc: 0.5664 - val_loss: 36.0830 - val_acc: 0.7532\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4933 - acc: 0.5664 - val_loss: 36.0805 - val_acc: 0.7532\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4886 - acc: 0.5664 - val_loss: 36.0779 - val_acc: 0.7532\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4840 - acc: 0.5664 - val_loss: 36.0753 - val_acc: 0.7532\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4793 - acc: 0.5664 - val_loss: 36.0727 - val_acc: 0.7532\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4746 - acc: 0.5664 - val_loss: 36.0702 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4700 - acc: 0.5664 - val_loss: 36.0676 - val_acc: 0.7532\n",
            "Epoch 19/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4653 - acc: 0.5664 - val_loss: 36.0650 - val_acc: 0.7532\n",
            "Epoch 20/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4607 - acc: 0.5664 - val_loss: 36.0625 - val_acc: 0.7532\n",
            "Epoch 21/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4561 - acc: 0.5664 - val_loss: 36.0599 - val_acc: 0.7532\n",
            "Epoch 22/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4514 - acc: 0.5664 - val_loss: 36.0573 - val_acc: 0.7532\n",
            "Epoch 23/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4468 - acc: 0.5664 - val_loss: 36.0547 - val_acc: 0.7532\n",
            "Epoch 24/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4420 - acc: 0.5664 - val_loss: 36.0522 - val_acc: 0.7532\n",
            "Epoch 25/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4374 - acc: 0.5664 - val_loss: 36.0496 - val_acc: 0.7532\n",
            "Epoch 26/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4328 - acc: 0.5664 - val_loss: 36.0470 - val_acc: 0.7532\n",
            "Epoch 27/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4281 - acc: 0.5664 - val_loss: 36.0445 - val_acc: 0.7532\n",
            "Epoch 28/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4234 - acc: 0.5664 - val_loss: 36.0419 - val_acc: 0.7532\n",
            "Epoch 29/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4188 - acc: 0.5664 - val_loss: 36.0393 - val_acc: 0.7532\n",
            "Epoch 30/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4142 - acc: 0.5664 - val_loss: 36.0367 - val_acc: 0.7532\n",
            "Epoch 31/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4095 - acc: 0.5664 - val_loss: 36.0341 - val_acc: 0.7532\n",
            "Epoch 32/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4048 - acc: 0.5664 - val_loss: 36.0316 - val_acc: 0.7532\n",
            "Epoch 33/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.4002 - acc: 0.5664 - val_loss: 36.0290 - val_acc: 0.7532\n",
            "Epoch 34/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3955 - acc: 0.5664 - val_loss: 36.0264 - val_acc: 0.7532\n",
            "Epoch 35/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3909 - acc: 0.5664 - val_loss: 36.0239 - val_acc: 0.7532\n",
            "Epoch 36/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3863 - acc: 0.5664 - val_loss: 36.0215 - val_acc: 0.7532\n",
            "Epoch 37/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3818 - acc: 0.5664 - val_loss: 36.0190 - val_acc: 0.7532\n",
            "Epoch 38/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3772 - acc: 0.5664 - val_loss: 36.0165 - val_acc: 0.7532\n",
            "Epoch 39/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3726 - acc: 0.5664 - val_loss: 36.0140 - val_acc: 0.7532\n",
            "Epoch 40/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3680 - acc: 0.5664 - val_loss: 36.0116 - val_acc: 0.7532\n",
            "Epoch 41/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3634 - acc: 0.5664 - val_loss: 36.0091 - val_acc: 0.7532\n",
            "Epoch 42/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3589 - acc: 0.5664 - val_loss: 36.0066 - val_acc: 0.7532\n",
            "Epoch 43/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3543 - acc: 0.5664 - val_loss: 36.0042 - val_acc: 0.7532\n",
            "Epoch 44/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3498 - acc: 0.5664 - val_loss: 36.0018 - val_acc: 0.7532\n",
            "Epoch 45/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3453 - acc: 0.5664 - val_loss: 35.9995 - val_acc: 0.7532\n",
            "Epoch 46/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3408 - acc: 0.5664 - val_loss: 35.9970 - val_acc: 0.7532\n",
            "Epoch 47/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3362 - acc: 0.5664 - val_loss: 35.9947 - val_acc: 0.7532\n",
            "Epoch 48/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3317 - acc: 0.5664 - val_loss: 35.9923 - val_acc: 0.7532\n",
            "Epoch 49/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3272 - acc: 0.5664 - val_loss: 35.9899 - val_acc: 0.7532\n",
            "Epoch 50/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3227 - acc: 0.5664 - val_loss: 35.9875 - val_acc: 0.7532\n",
            "Epoch 51/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3183 - acc: 0.5664 - val_loss: 35.9851 - val_acc: 0.7532\n",
            "Epoch 52/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3137 - acc: 0.5664 - val_loss: 35.9828 - val_acc: 0.7532\n",
            "Epoch 53/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3092 - acc: 0.5664 - val_loss: 35.9804 - val_acc: 0.7532\n",
            "Epoch 54/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3047 - acc: 0.5664 - val_loss: 35.9780 - val_acc: 0.7532\n",
            "Epoch 55/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.3002 - acc: 0.5664 - val_loss: 35.9756 - val_acc: 0.7532\n",
            "Epoch 56/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2957 - acc: 0.5664 - val_loss: 35.9732 - val_acc: 0.7532\n",
            "Epoch 57/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2912 - acc: 0.5664 - val_loss: 35.9708 - val_acc: 0.7532\n",
            "Epoch 58/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2867 - acc: 0.5664 - val_loss: 35.9684 - val_acc: 0.7532\n",
            "Epoch 59/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2822 - acc: 0.5664 - val_loss: 35.9660 - val_acc: 0.7532\n",
            "Epoch 60/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2776 - acc: 0.5664 - val_loss: 35.9637 - val_acc: 0.7532\n",
            "Epoch 61/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2731 - acc: 0.5664 - val_loss: 35.9613 - val_acc: 0.7532\n",
            "Epoch 62/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2687 - acc: 0.5664 - val_loss: 35.9589 - val_acc: 0.7532\n",
            "Epoch 63/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2641 - acc: 0.5664 - val_loss: 35.9565 - val_acc: 0.7532\n",
            "Epoch 64/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2596 - acc: 0.5664 - val_loss: 35.9541 - val_acc: 0.7532\n",
            "Epoch 65/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2551 - acc: 0.5664 - val_loss: 35.9517 - val_acc: 0.7532\n",
            "Epoch 66/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2506 - acc: 0.5664 - val_loss: 35.9493 - val_acc: 0.7532\n",
            "Epoch 67/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2461 - acc: 0.5664 - val_loss: 35.9470 - val_acc: 0.7532\n",
            "Epoch 68/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2415 - acc: 0.5664 - val_loss: 35.9446 - val_acc: 0.7532\n",
            "Epoch 69/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2371 - acc: 0.5664 - val_loss: 35.9422 - val_acc: 0.7532\n",
            "Epoch 70/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2325 - acc: 0.5664 - val_loss: 35.9398 - val_acc: 0.7532\n",
            "Epoch 71/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2280 - acc: 0.5664 - val_loss: 35.9374 - val_acc: 0.7532\n",
            "Epoch 72/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2235 - acc: 0.5664 - val_loss: 35.9350 - val_acc: 0.7532\n",
            "Epoch 73/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2190 - acc: 0.5664 - val_loss: 35.9326 - val_acc: 0.7532\n",
            "Epoch 74/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2145 - acc: 0.5664 - val_loss: 35.9302 - val_acc: 0.7532\n",
            "Epoch 75/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2100 - acc: 0.5664 - val_loss: 35.9279 - val_acc: 0.7532\n",
            "Epoch 76/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2055 - acc: 0.5664 - val_loss: 35.9254 - val_acc: 0.7532\n",
            "Epoch 77/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.2010 - acc: 0.5664 - val_loss: 35.9231 - val_acc: 0.7532\n",
            "Epoch 78/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1965 - acc: 0.5664 - val_loss: 35.9207 - val_acc: 0.7532\n",
            "Epoch 79/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1920 - acc: 0.5664 - val_loss: 35.9183 - val_acc: 0.7532\n",
            "Epoch 80/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1874 - acc: 0.5664 - val_loss: 35.9159 - val_acc: 0.7532\n",
            "Epoch 81/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1829 - acc: 0.5664 - val_loss: 35.9136 - val_acc: 0.7532\n",
            "Epoch 82/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1784 - acc: 0.5664 - val_loss: 35.9111 - val_acc: 0.7532\n",
            "Epoch 83/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1739 - acc: 0.5664 - val_loss: 35.9088 - val_acc: 0.7532\n",
            "Epoch 84/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1694 - acc: 0.5664 - val_loss: 35.9064 - val_acc: 0.7532\n",
            "Epoch 85/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1649 - acc: 0.5664 - val_loss: 35.9040 - val_acc: 0.7532\n",
            "Epoch 86/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1604 - acc: 0.5664 - val_loss: 35.9016 - val_acc: 0.7532\n",
            "Epoch 87/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1559 - acc: 0.5664 - val_loss: 35.8992 - val_acc: 0.7532\n",
            "Epoch 88/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1514 - acc: 0.5664 - val_loss: 35.8968 - val_acc: 0.7532\n",
            "Epoch 89/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1469 - acc: 0.5664 - val_loss: 35.8944 - val_acc: 0.7532\n",
            "Epoch 90/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1423 - acc: 0.5664 - val_loss: 35.8920 - val_acc: 0.7532\n",
            "Epoch 91/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1379 - acc: 0.5664 - val_loss: 35.8897 - val_acc: 0.7532\n",
            "Epoch 92/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1333 - acc: 0.5664 - val_loss: 35.8873 - val_acc: 0.7532\n",
            "Epoch 93/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1288 - acc: 0.5664 - val_loss: 35.8849 - val_acc: 0.7532\n",
            "Epoch 94/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1243 - acc: 0.5664 - val_loss: 35.8825 - val_acc: 0.7532\n",
            "Epoch 95/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1198 - acc: 0.5664 - val_loss: 35.8801 - val_acc: 0.7532\n",
            "Epoch 96/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1152 - acc: 0.5664 - val_loss: 35.8777 - val_acc: 0.7532\n",
            "Epoch 97/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1107 - acc: 0.5664 - val_loss: 35.8753 - val_acc: 0.7532\n",
            "Epoch 98/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1062 - acc: 0.5664 - val_loss: 35.8729 - val_acc: 0.7532\n",
            "Epoch 99/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.1017 - acc: 0.5664 - val_loss: 35.8705 - val_acc: 0.7532\n",
            "Epoch 100/100\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 75.0972 - acc: 0.5664 - val_loss: 35.8681 - val_acc: 0.7532\n",
            "saving model\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 384, 384, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 384, 384, 3)       228       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 384, 384, 3)       228       \n",
            "=================================================================\n",
            "Total params: 456\n",
            "Trainable params: 456\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-986cdd126622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlotTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzoom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'PlotTraining' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVjcXJIi9Dfq",
        "colab_type": "text"
      },
      "source": [
        "load if a model if you want\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-87Hh1KFgg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load if you can\n",
        "model = load_model(\"/content/drive/My Drive/models/last_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h93JqBcT81eD",
        "colab_type": "text"
      },
      "source": [
        "save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwwd5XUv80xE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/models/last_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}